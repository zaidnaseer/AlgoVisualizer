[
    {
        "id": 1,
        "topic": "Sorting",
        "algorithm": "Bubble Sort",
        "difficulty": "Easy",
        "question": "What is the basic idea of Bubble Sort?",
        "options": [
            "Bubble Sort compares and processes elements step by step",
            "It uses dynamic programming",
            "It uses hashing",
            "It uses recursion with memoization"
        ],
        "correctAnswer": 0,
        "explanation": "Bubble Sort is based on a fundamental step-by-step process, not advanced techniques like DP or hashing."
    },
    {
        "id": 2,
        "topic": "Sorting",
        "algorithm": "Bubble Sort",
        "difficulty": "Easy",
        "question": "What is the best case time complexity of Bubble Sort?",
        "options": [
            "O(1)",
            "O(n)",
            "O(n log n)",
            "O(n\u00b2)"
        ],
        "correctAnswer": 1,
        "explanation": "In the best case, Bubble Sort can often achieve O(n), especially when data is already partially structured."
    },
    {
        "id": 3,
        "topic": "Sorting",
        "algorithm": "Bubble Sort",
        "difficulty": "Medium",
        "question": "What is the average case time complexity of Bubble Sort?",
        "options": [
            "O(n^2)",
            "O(n log n)",
            "O(n\u00b2)",
            "O(log n)"
        ],
        "correctAnswer": 0,
        "explanation": "Typically, Bubble Sort has an average case of O(n^2)."
    },
    {
        "id": 4,
        "topic": "Sorting",
        "algorithm": "Bubble Sort",
        "difficulty": "Medium",
        "question": "Which data structure is commonly associated with Bubble Sort?",
        "options": [
            "Array",
            "Stack",
            "Queue",
            "Tree"
        ],
        "correctAnswer": 0,
        "explanation": "Bubble Sort usually works directly on arrays in basic implementations."
    },
    {
        "id": 5,
        "topic": "Sorting",
        "algorithm": "Bubble Sort",
        "difficulty": "Hard",
        "question": "What is the worst case space complexity of Bubble Sort?",
        "options": [
            "O(1)",
            "O(log n)",
            "O(n)",
            "O(n\u00b2)"
        ],
        "correctAnswer": 0,
        "explanation": "Bubble Sort requires O(1) extra space in the worst case."
    },
    {
        "id": 6,
        "topic": "Sorting",
        "algorithm": "Bubble Sort",
        "difficulty": "Hard",
        "question": "What makes Bubble Sort less efficient compared to advanced algorithms?",
        "options": [
            "Higher time complexity",
            "More space usage",
            "Not adaptive",
            "All of the above"
        ],
        "correctAnswer": 3,
        "explanation": "Bubble Sort is often less efficient due to multiple factors like higher time complexity, space usage, and lack of adaptability."
    },
    {
        "id": 7,
        "topic": "Sorting",
        "algorithm": "Selection Sort",
        "difficulty": "Easy",
        "question": "What is the basic idea of Selection Sort?",
        "options": [
            "Selection Sort compares and processes elements step by step",
            "It uses dynamic programming",
            "It uses hashing",
            "It uses recursion with memoization"
        ],
        "correctAnswer": 0,
        "explanation": "Selection Sort is based on a fundamental step-by-step process, not advanced techniques like DP or hashing."
    },
    {
        "id": 8,
        "topic": "Sorting",
        "algorithm": "Selection Sort",
        "difficulty": "Easy",
        "question": "What is the best case time complexity of Selection Sort?",
        "options": [
            "O(1)",
            "O(n)",
            "O(n log n)",
            "O(n\u00b2)"
        ],
        "correctAnswer": 1,
        "explanation": "In the best case, Selection Sort can often achieve O(n), especially when data is already partially structured."
    },
    {
        "id": 9,
        "topic": "Sorting",
        "algorithm": "Selection Sort",
        "difficulty": "Medium",
        "question": "What is the average case time complexity of Selection Sort?",
        "options": [
            "O(n)",
            "O(n log n)",
            "O(n\u00b2)",
            "O(log n)"
        ],
        "correctAnswer": 1,
        "explanation": "Typically, Selection Sort has an average case of O(n log n)."
    },
    {
        "id": 10,
        "topic": "Sorting",
        "algorithm": "Selection Sort",
        "difficulty": "Medium",
        "question": "Which data structure is commonly associated with Selection Sort?",
        "options": [
            "Array",
            "Stack",
            "Queue",
            "Tree"
        ],
        "correctAnswer": 0,
        "explanation": "Selection Sort usually works directly on arrays in basic implementations."
    },
    {
        "id": 11,
        "topic": "Sorting",
        "algorithm": "Selection Sort",
        "difficulty": "Hard",
        "question": "What is the worst case space complexity of Selection Sort?",
        "options": [
            "O(1)",
            "O(log n)",
            "O(n)",
            "O(n\u00b2)"
        ],
        "correctAnswer": 0,
        "explanation": "Selection Sort requires O(1) extra space in the worst case."
    },
    {
        "id": 12,
        "topic": "Sorting",
        "algorithm": "Selection Sort",
        "difficulty": "Hard",
        "question": "What makes Selection Sort less efficient compared to advanced algorithms?",
        "options": [
            "Higher time complexity",
            "More space usage",
            "Not adaptive",
            "All of the above"
        ],
        "correctAnswer": 3,
        "explanation": "Selection Sort is often less efficient due to multiple factors like higher time complexity, space usage, and lack of adaptability."
    },
    {
        "id": 13,
        "topic": "Sorting",
        "algorithm": "Insertion Sort",
        "difficulty": "Easy",
        "question": "What is the basic idea of Insertion Sort?",
        "options": [
            "Insertion Sort compares and processes elements step by step",
            "It uses dynamic programming",
            "It uses hashing",
            "It uses recursion with memoization"
        ],
        "correctAnswer": 0,
        "explanation": "Insertion Sort is based on a fundamental step-by-step process, not advanced techniques like DP or hashing."
    },
    {
        "id": 14,
        "topic": "Sorting",
        "algorithm": "Insertion Sort",
        "difficulty": "Easy",
        "question": "What is the best case time complexity of Insertion Sort?",
        "options": [
            "O(1)",
            "O(n)",
            "O(n log n)",
            "O(n\u00b2)"
        ],
        "correctAnswer": 1,
        "explanation": "In the best case, Insertion Sort can often achieve O(n), especially when data is already partially structured."
    },
    {
        "id": 15,
        "topic": "Sorting",
        "algorithm": "Insertion Sort",
        "difficulty": "Medium",
        "question": "What is the average case time complexity of Insertion Sort?",
        "options": [
            "O(n)",
            "O(n log n)",
            "O(n\u00b2)",
            "O(n^2)"
        ],
        "correctAnswer": 3,
        "explanation": "Typically, Insertion Sort has an average case of O(n^2)."
    },
    {
        "id": 16,
        "topic": "Sorting",
        "algorithm": "Insertion Sort",
        "difficulty": "Medium",
        "question": "Which data structure is commonly associated with Insertion Sort?",
        "options": [
            "Array",
            "Stack",
            "Queue",
            "Tree"
        ],
        "correctAnswer": 0,
        "explanation": "Insertion Sort usually works directly on arrays in basic implementations."
    },
    {
        "id": 17,
        "topic": "Sorting",
        "algorithm": "Insertion Sort",
        "difficulty": "Hard",
        "question": "What is the worst case space complexity of Insertion Sort?",
        "options": [
            "O(1)",
            "O(log n)",
            "O(n)",
            "O(n\u00b2)"
        ],
        "correctAnswer": 0,
        "explanation": "Insertion Sort requires O(1) extra space in the worst case."
    },
    {
        "id": 18,
        "topic": "Sorting",
        "algorithm": "Insertion Sort",
        "difficulty": "Hard",
        "question": "What makes Insertion Sort less efficient compared to advanced algorithms?",
        "options": [
            "Higher time complexity",
            "More space usage",
            "Not adaptive",
            "All of the above"
        ],
        "correctAnswer": 3,
        "explanation": "Insertion Sort is often less efficient due to multiple factors like higher time complexity, space usage, and lack of adaptability."
    },
    {
        "id": 19,
        "topic": "Sorting",
        "algorithm": "Merge Sort",
        "difficulty": "Easy",
        "question": "What is the basic idea of Merge Sort?",
        "options": [
            "Merge Sort compares and processes elements step by step",
            "It uses dynamic programming",
            "It uses hashing",
            "It uses recursion with memoization"
        ],
        "correctAnswer": 0,
        "explanation": "Merge Sort is based on a fundamental step-by-step process, not advanced techniques like DP or hashing."
    },
    {
        "id": 20,
        "topic": "Sorting",
        "algorithm": "Merge Sort",
        "difficulty": "Easy",
        "question": "What is the best case time complexity of Merge Sort?",
        "options": [
            "O(1)",
            "O(n)",
            "O(n log n)",
            "O(n\u00b2)"
        ],
        "correctAnswer": 1,
        "explanation": "In the best case, Merge Sort can often achieve O(n), especially when data is already partially structured."
    },
    {
        "id": 21,
        "topic": "Sorting",
        "algorithm": "Merge Sort",
        "difficulty": "Medium",
        "question": "What is the average case time complexity of Merge Sort?",
        "options": [
            "O(n)",
            "O(n log n)",
            "O(n\u00b2)",
            "O(log n)"
        ],
        "correctAnswer": 1,
        "explanation": "Typically, Merge Sort has an average case of O(n log n)."
    },
    {
        "id": 22,
        "topic": "Sorting",
        "algorithm": "Merge Sort",
        "difficulty": "Medium",
        "question": "Which data structure is commonly associated with Merge Sort?",
        "options": [
            "Array",
            "Stack",
            "Queue",
            "Tree"
        ],
        "correctAnswer": 0,
        "explanation": "Merge Sort usually works directly on arrays in basic implementations."
    },
    {
        "id": 23,
        "topic": "Sorting",
        "algorithm": "Merge Sort",
        "difficulty": "Hard",
        "question": "What is the worst case space complexity of Merge Sort?",
        "options": [
            "O(1)",
            "O(log n)",
            "O(n)",
            "O(n\u00b2)"
        ],
        "correctAnswer": 2,
        "explanation": "Merge Sort requires O(n) extra space in the worst case."
    },
    {
        "id": 24,
        "topic": "Sorting",
        "algorithm": "Merge Sort",
        "difficulty": "Hard",
        "question": "What makes Merge Sort less efficient compared to advanced algorithms?",
        "options": [
            "Higher time complexity",
            "More space usage",
            "Not adaptive",
            "All of the above"
        ],
        "correctAnswer": 3,
        "explanation": "Merge Sort is often less efficient due to multiple factors like higher time complexity, space usage, and lack of adaptability."
    },
    {
        "id": 25,
        "topic": "Sorting",
        "algorithm": "Quick Sort",
        "difficulty": "Easy",
        "question": "What is the basic idea of Quick Sort?",
        "options": [
            "Quick Sort compares and processes elements step by step",
            "It uses dynamic programming",
            "It uses hashing",
            "It uses recursion with memoization"
        ],
        "correctAnswer": 0,
        "explanation": "Quick Sort is based on a fundamental step-by-step process, not advanced techniques like DP or hashing."
    },
    {
        "id": 26,
        "topic": "Sorting",
        "algorithm": "Quick Sort",
        "difficulty": "Easy",
        "question": "What is the best case time complexity of Quick Sort?",
        "options": [
            "O(1)",
            "O(n)",
            "O(n log n)",
            "O(n\u00b2)"
        ],
        "correctAnswer": 1,
        "explanation": "In the best case, Quick Sort can often achieve O(n), especially when data is already partially structured."
    },
    {
        "id": 27,
        "topic": "Sorting",
        "algorithm": "Quick Sort",
        "difficulty": "Medium",
        "question": "What is the average case time complexity of Quick Sort?",
        "options": [
            "O(n)",
            "O(n log n)",
            "O(n\u00b2)",
            "O(log n)"
        ],
        "correctAnswer": 1,
        "explanation": "Typically, Quick Sort has an average case of O(n log n)."
    },
    {
        "id": 28,
        "topic": "Sorting",
        "algorithm": "Quick Sort",
        "difficulty": "Medium",
        "question": "Which data structure is commonly associated with Quick Sort?",
        "options": [
            "Array",
            "Stack",
            "Queue",
            "Tree"
        ],
        "correctAnswer": 0,
        "explanation": "Quick Sort usually works directly on arrays in basic implementations."
    },
    {
        "id": 29,
        "topic": "Sorting",
        "algorithm": "Quick Sort",
        "difficulty": "Hard",
        "question": "What is the worst case space complexity of Quick Sort?",
        "options": [
            "O(1)",
            "O(log n)",
            "O(n)",
            "O(n\u00b2)"
        ],
        "correctAnswer": 0,
        "explanation": "Quick Sort requires O(1) extra space in the worst case."
    },
    {
        "id": 30,
        "topic": "Sorting",
        "algorithm": "Quick Sort",
        "difficulty": "Hard",
        "question": "What makes Quick Sort less efficient compared to advanced algorithms?",
        "options": [
            "Higher time complexity",
            "More space usage",
            "Not adaptive",
            "All of the above"
        ],
        "correctAnswer": 3,
        "explanation": "Quick Sort is often less efficient due to multiple factors like higher time complexity, space usage, and lack of adaptability."
    },
    {
        "id": 31,
        "topic": "Sorting",
        "algorithm": "Tim Sort",
        "difficulty": "Easy",
        "question": "What is the basic idea of Tim Sort?",
        "options": [
            "Tim Sort compares and processes elements step by step",
            "It uses dynamic programming",
            "It uses hashing",
            "It uses recursion with memoization"
        ],
        "correctAnswer": 0,
        "explanation": "Tim Sort is based on a fundamental step-by-step process, not advanced techniques like DP or hashing."
    },
    {
        "id": 32,
        "topic": "Sorting",
        "algorithm": "Tim Sort",
        "difficulty": "Easy",
        "question": "What is the best case time complexity of Tim Sort?",
        "options": [
            "O(1)",
            "O(n)",
            "O(n log n)",
            "O(n\u00b2)"
        ],
        "correctAnswer": 1,
        "explanation": "In the best case, Tim Sort can often achieve O(n), especially when data is already partially structured."
    },
    {
        "id": 33,
        "topic": "Sorting",
        "algorithm": "Tim Sort",
        "difficulty": "Medium",
        "question": "What is the average case time complexity of Tim Sort?",
        "options": [
            "O(n)",
            "O(n log n)",
            "O(n\u00b2)",
            "O(log n)"
        ],
        "correctAnswer": 1,
        "explanation": "Typically, Tim Sort has an average case of O(n log n)."
    },
    {
        "id": 34,
        "topic": "Sorting",
        "algorithm": "Tim Sort",
        "difficulty": "Medium",
        "question": "Which data structure is commonly associated with Tim Sort?",
        "options": [
            "Array",
            "Stack",
            "Queue",
            "Tree"
        ],
        "correctAnswer": 0,
        "explanation": "Tim Sort usually works directly on arrays in basic implementations."
    },
    {
        "id": 35,
        "topic": "Sorting",
        "algorithm": "Tim Sort",
        "difficulty": "Hard",
        "question": "What is the worst case space complexity of Tim Sort?",
        "options": [
            "O(1)",
            "O(log n)",
            "O(n)",
            "O(n\u00b2)"
        ],
        "correctAnswer": 0,
        "explanation": "Tim Sort requires O(1) extra space in the worst case."
    },
    {
        "id": 36,
        "topic": "Sorting",
        "algorithm": "Tim Sort",
        "difficulty": "Hard",
        "question": "What makes Tim Sort less efficient compared to advanced algorithms?",
        "options": [
            "Higher time complexity",
            "More space usage",
            "Not adaptive",
            "All of the above"
        ],
        "correctAnswer": 3,
        "explanation": "Tim Sort is often less efficient due to multiple factors like higher time complexity, space usage, and lack of adaptability."
    },
    {
        "id": 37,
        "topic": "Sorting",
        "algorithm": "Intro Sort",
        "difficulty": "Easy",
        "question": "What is the basic idea of Intro Sort?",
        "options": [
            "Intro Sort compares and processes elements step by step",
            "It uses dynamic programming",
            "It uses hashing",
            "It uses recursion with memoization"
        ],
        "correctAnswer": 0,
        "explanation": "Intro Sort is based on a fundamental step-by-step process, not advanced techniques like DP or hashing."
    },
    {
        "id": 38,
        "topic": "Sorting",
        "algorithm": "Intro Sort",
        "difficulty": "Easy",
        "question": "What is the best case time complexity of Intro Sort?",
        "options": [
            "O(1)",
            "O(n)",
            "O(n log n)",
            "O(n\u00b2)"
        ],
        "correctAnswer": 1,
        "explanation": "In the best case, Intro Sort can often achieve O(n), especially when data is already partially structured."
    },
    {
        "id": 39,
        "topic": "Sorting",
        "algorithm": "Intro Sort",
        "difficulty": "Medium",
        "question": "What is the average case time complexity of Intro Sort?",
        "options": [
            "O(n)",
            "O(n log n)",
            "O(n\u00b2)",
            "O(log n)"
        ],
        "correctAnswer": 1,
        "explanation": "Typically, Intro Sort has an average case of O(n log n)."
    },
    {
        "id": 40,
        "topic": "Sorting",
        "algorithm": "Intro Sort",
        "difficulty": "Medium",
        "question": "Which data structure is commonly associated with Intro Sort?",
        "options": [
            "Array",
            "Stack",
            "Queue",
            "Tree"
        ],
        "correctAnswer": 0,
        "explanation": "Intro Sort usually works directly on arrays in basic implementations."
    },
    {
        "id": 41,
        "topic": "Sorting",
        "algorithm": "Intro Sort",
        "difficulty": "Hard",
        "question": "What is the worst case space complexity of Intro Sort?",
        "options": [
            "O(1)",
            "O(log n)",
            "O(n)",
            "O(n\u00b2)"
        ],
        "correctAnswer": 0,
        "explanation": "Intro Sort requires O(1) extra space in the worst case."
    },
    {
        "id": 42,
        "topic": "Sorting",
        "algorithm": "Intro Sort",
        "difficulty": "Hard",
        "question": "What makes Intro Sort less efficient compared to advanced algorithms?",
        "options": [
            "Higher time complexity",
            "More space usage",
            "Not adaptive",
            "All of the above"
        ],
        "correctAnswer": 3,
        "explanation": "Intro Sort is often less efficient due to multiple factors like higher time complexity, space usage, and lack of adaptability."
    },
    {
        "id": 43,
        "topic": "Sorting",
        "algorithm": "Shell Sort",
        "difficulty": "Easy",
        "question": "What is the basic idea of Shell Sort?",
        "options": [
            "Shell Sort compares and processes elements step by step",
            "It uses dynamic programming",
            "It uses hashing",
            "It uses recursion with memoization"
        ],
        "correctAnswer": 0,
        "explanation": "Shell Sort is based on a fundamental step-by-step process, not advanced techniques like DP or hashing."
    },
    {
        "id": 44,
        "topic": "Sorting",
        "algorithm": "Shell Sort",
        "difficulty": "Easy",
        "question": "What is the best case time complexity of Shell Sort?",
        "options": [
            "O(1)",
            "O(n)",
            "O(n log n)",
            "O(n\u00b2)"
        ],
        "correctAnswer": 1,
        "explanation": "In the best case, Shell Sort can often achieve O(n), especially when data is already partially structured."
    },
    {
        "id": 45,
        "topic": "Sorting",
        "algorithm": "Shell Sort",
        "difficulty": "Medium",
        "question": "What is the average case time complexity of Shell Sort?",
        "options": [
            "O(n)",
            "O(n log n)",
            "O(n\u00b2)",
            "O(log n)"
        ],
        "correctAnswer": 1,
        "explanation": "Typically, Shell Sort has an average case of O(n log n)."
    },
    {
        "id": 46,
        "topic": "Sorting",
        "algorithm": "Shell Sort",
        "difficulty": "Medium",
        "question": "Which data structure is commonly associated with Shell Sort?",
        "options": [
            "Array",
            "Stack",
            "Queue",
            "Tree"
        ],
        "correctAnswer": 0,
        "explanation": "Shell Sort usually works directly on arrays in basic implementations."
    },
    {
        "id": 47,
        "topic": "Sorting",
        "algorithm": "Shell Sort",
        "difficulty": "Hard",
        "question": "What is the worst case space complexity of Shell Sort?",
        "options": [
            "O(1)",
            "O(log n)",
            "O(n)",
            "O(n\u00b2)"
        ],
        "correctAnswer": 0,
        "explanation": "Shell Sort requires O(1) extra space in the worst case."
    },
    {
        "id": 48,
        "topic": "Sorting",
        "algorithm": "Shell Sort",
        "difficulty": "Hard",
        "question": "What makes Shell Sort less efficient compared to advanced algorithms?",
        "options": [
            "Higher time complexity",
            "More space usage",
            "Not adaptive",
            "All of the above"
        ],
        "correctAnswer": 3,
        "explanation": "Shell Sort is often less efficient due to multiple factors like higher time complexity, space usage, and lack of adaptability."
    },
    {
        "id": 49,
        "topic": "Searching",
        "algorithm": "Linear Search",
        "difficulty": "Easy",
        "question": "What is the basic idea of Linear Search?",
        "options": [
            "Linear Search compares and processes elements step by step",
            "It uses dynamic programming",
            "It uses hashing",
            "It uses recursion with memoization"
        ],
        "correctAnswer": 0,
        "explanation": "Linear Search is based on a fundamental step-by-step process, not advanced techniques like DP or hashing."
    },
    {
        "id": 50,
        "topic": "Searching",
        "algorithm": "Linear Search",
        "difficulty": "Easy",
        "question": "What is the best case time complexity of Linear Search?",
        "options": [
            "O(1)",
            "O(n)",
            "O(n log n)",
            "O(n\u00b2)"
        ],
        "correctAnswer": 0,
        "explanation": "In the best case, Linear Search can often achieve O(1), especially when target is the first element in array."
    },
    {
        "id": 51,
        "topic": "Searching",
        "algorithm": "Linear Search",
        "difficulty": "Medium",
        "question": "What is the average case time complexity of Linear Search?",
        "options": [
            "O(n)",
            "O(n log n)",
            "O(n\u00b2)",
            "O(log n)"
        ],
        "correctAnswer": 0,
        "explanation": "Typically, Linear Search has an average case of O(n)."
    },
    {
        "id": 52,
        "topic": "Searching",
        "algorithm": "Linear Search",
        "difficulty": "Medium",
        "question": "Which data structure is commonly associated with Linear Search?",
        "options": [
            "Array",
            "Stack",
            "Queue",
            "Tree"
        ],
        "correctAnswer": 0,
        "explanation": "Linear Search usually works directly on arrays in basic implementations."
    },
    {
        "id": 53,
        "topic": "Searching",
        "algorithm": "Linear Search",
        "difficulty": "Hard",
        "question": "What is the worst case time complexity of Linear Search?",
        "options": [
            "O(1)",
            "O(log n)",
            "O(n)",
            "O(n\u00b2)"
        ],
        "correctAnswer": 2,
        "explanation": "Linear Search takes O(n) time to search through the entire array in the worst case."
    },
    {
        "id": 54,
        "topic": "Searching",
        "algorithm": "Linear Search",
        "difficulty": "Hard",
        "question": "What makes Linear Search less efficient compared to advanced algorithms?",
        "options": [
            "Higher time complexity",
            "More space usage",
            "Not adaptive",
            "All of the above"
        ],
        "correctAnswer": 3,
        "explanation": "Linear Search is often less efficient due to multiple factors like higher time complexity, space usage, and lack of adaptability."
    },
    {
        "id": 55,
        "topic": "Searching",
        "algorithm": "Binary Search",
        "difficulty": "Easy",
        "question": "What is the basic idea of Binary Search?",
        "options": [
            "Binary Search compares and processes elements step by step",
            "It uses dynamic programming",
            "It uses hashing",
            "It uses recursion with memoization"
        ],
        "correctAnswer": 0,
        "explanation": "Binary Search is based on a fundamental step-by-step process, not advanced techniques like DP or hashing."
    },
    {
        "id": 56,
        "topic": "Searching",
        "algorithm": "Binary Search",
        "difficulty": "Easy",
        "question": "What is the best case time complexity of Binary Search?",
        "options": [
            "O(1)",
            "O(n)",
            "O(n log n)",
            "O(n\u00b2)"
        ],
        "correctAnswer": 1,
        "explanation": "In the best case, Binary Search can often achieve O(1), especially when data is already partially structured."
    },
    {
        "id": 57,
        "topic": "Searching",
        "algorithm": "Binary Search",
        "difficulty": "Medium",
        "question": "What is the average case time complexity of Binary Search?",
        "options": [
            "O(n)",
            "O(n log n)",
            "O(n\u00b2)",
            "O(log n)"
        ],
        "correctAnswer": 3,
        "explanation": "Typically, Binary Search has an average case of O(log n)."
    },
    {
        "id": 58,
        "topic": "Searching",
        "algorithm": "Binary Search",
        "difficulty": "Medium",
        "question": "Which data structure is commonly associated with Binary Search?",
        "options": [
            "Array",
            "Stack",
            "Queue",
            "Tree"
        ],
        "correctAnswer": 0,
        "explanation": "Binary Search usually works directly on arrays in basic implementations."
    },
    {
        "id": 59,
        "topic": "Searching",
        "algorithm": "Binary Search",
        "difficulty": "Hard",
        "question": "What is the worst case space complexity of Binary Search?",
        "options": [
            "O(1)",
            "O(log n)",
            "O(n)",
            "O(n\u00b2)"
        ],
        "correctAnswer": 1,
        "explanation": "Binary Search requires O(log n) time complexity in the worst case."
    },
    {
        "id": 60,
        "topic": "Searching",
        "algorithm": "Binary Search",
        "difficulty": "Hard",
        "question": "What makes Binary Search less efficient compared to advanced algorithms?",
        "options": [
            "Higher time complexity",
            "More space usage",
            "Not adaptive",
            "All of the above"
        ],
        "correctAnswer": 3,
        "explanation": "Binary Search is often less efficient due to multiple factors like higher time complexity, space usage, and lack of adaptability."
    },
    
  {
    "id": 67,
    "topic": "Searching",
    "algorithm": "Search in Databases",
    "difficulty": "Hard",
    "question": "Which searching technique is typically used in databases to speed up retrieval?",
    "options": [
      "Linear Search",
      "Binary Search",
      "Indexing with B-trees or Hashing",
      "Graph Search"
    ],
    "correctAnswer": 2,
    "explanation": "Databases use indexing techniques like B-trees and hashing to allow fast retrieval of records based on keys."
  },
  {
    "id": 68,
    "topic": "Searching",
    "algorithm": "File Systems",
    "difficulty": "Hard",
    "question": "How do modern file systems optimize search for files by name?",
    "options": [
      "Using Trie-based indexing",
      "Using Linear Search on all files",
      "Storing filenames in a queue",
      "Performing BFS on disk blocks"
    ],
    "correctAnswer": 0,
    "explanation": "Many modern file systems use Trie-like or hash-based structures to optimize filename lookups, especially for autocomplete and path resolution."
  },
  {
    "id": 69,
    "topic": "Searching",
    "algorithm": "Search Engines",
    "difficulty": "Hard",
    "question": "Which data structure is heavily used in search engines to map keywords to documents?",
    "options": [
      "Linked List",
      "Hash Table",
      "Inverted Index",
      "Binary Heap"
    ],
    "correctAnswer": 2,
    "explanation": "Search engines use an inverted index, which maps keywords to the list of documents containing them, allowing fast keyword-based retrieval."
  },
  {
    "id": 70,
    "topic": "Searching",
    "algorithm": "Pattern Matching",
    "difficulty": "Hard",
    "question": "Which algorithm is commonly used for efficient substring search in large texts?",
    "options": [
      "Linear Search",
      "KMP Algorithm",
      "Quick Sort",
      "Depth First Search"
    ],
    "correctAnswer": 1,
    "explanation": "The Knuth-Morris-Pratt (KMP) algorithm preprocesses the pattern and performs efficient substring search without backtracking."
  },
  {
    "id": 71,
    "topic": "Searching",
    "algorithm": "Networking",
    "difficulty": "Hard",
    "question": "In routing tables, which searching technique is used to determine the best path?",
    "options": [
      "Linear Search through all routes",
      "Longest Prefix Match using Trie",
      "Depth-First Search",
      "Interpolation Search"
    ],
    "correctAnswer": 1,
    "explanation": "Routers use Longest Prefix Match, often implemented using a Trie, to find the most specific matching route in the routing table."
  },
  {
    "id": 72,
    "topic": "Searching",
    "algorithm": "Operating Systems",
    "difficulty": "Hard",
    "question": "How does an operating system quickly find a process in a process table?",
    "options": [
      "Using a sorted array with Binary Search",
      "Using a Hash Table for constant-time lookup",
      "Using Breadth First Search",
      "Using Exponential Search"
    ],
    "correctAnswer": 1,
    "explanation": "Most operating systems use hash tables to store and search for processes efficiently by process ID."
  },


{
    "id":78,
    "topic": "Searching",
    "algorithm": "Search in Graphs",
    "difficulty": "Hard",
    "question": "Which search algorithm is best suited for finding the shortest path in an unweighted graph?",
    "options": [
      "Depth First Search (DFS)",
      "Breadth First Search (BFS)",     
        "Dijkstra's Algorithm",
        "A* Search"
    ],
    "correctAnswer": 1,
    "explanation": "BFS is optimal for finding the shortest path in unweighted graphs as it explores all neighbors level by level." 
},
  {
    "id": 79,
    "topic": "Searching",
    "algorithm": "Linear Search",
    "difficulty": "Medium",
    "question": "Which of the following is the correct implementation of Linear Search in Python?",
    "options": [
      "def linear_search(arr, x):\n    for i in arr:\n        if arr[i] == x:\n            return i\n    return -1",
      "def linear_search(arr, x):\n    for i in range(len(arr)):\n        if arr[i] == x:\n            return i\n    return -1",
      "def linear_search(arr, x):\n    if x in arr:\n        return x\n    return -1",
      "def linear_search(arr, x):\n    return arr.index(x)"
    ],
    "correctAnswer": 1,
    "explanation": "Option 2 is the correct implementation using index-based iteration. Option 1 has a bug; 'i' is the element, not index."
  },
  {
    "id": 80,
    "topic": "Searching",
    "algorithm": "Binary Search",
    "difficulty": "Medium",
    "question": "Which of the following correctly implements Binary Search (iterative)?",
    "options": [
      "def binary_search(arr, x):\n    for i in range(len(arr)):\n        if arr[i] == x:\n            return i\n    return -1",
      "def binary_search(arr, x):\n    low = 0\n    high = len(arr) - 1\n    while low <= high:\n        mid = (low + high) // 2\n        if arr[mid] == x:\n            return mid\n        elif arr[mid] < x:\n            low = mid + 1\n        else:\n            high = mid - 1\n    return -1",
      "def binary_search(arr, x):\n    arr.sort()\n    return arr.index(x)",
      "def binary_search(arr, x):\n    return arr.find(x)"
    ],
    "correctAnswer": 1,
    "explanation": "Option 2 is the correct iterative Binary Search implementation. It requires the array to be sorted beforehand."
  },
{
    "id": 73,
    "topic": "Searching",
    "algorithm": "Linear Search",
    "difficulty": "Medium",
    "question": "In an unsorted array, what is the average number of comparisons Linear Search will make to find a target element?",
    "options": [
      "n/2",
      "n",
      "log n",
      "1"
    ],
    "correctAnswer": 0,
    "explanation": "On average, Linear Search will traverse about half of the elements to find the target, resulting in n/2 comparisons."
  },
  {
    "id": 81,
    "topic": "Searching",
    "algorithm": "Recursive Binary Search",
    "difficulty": "Medium",
    "question": "Which code snippet correctly implements Recursive Binary Search?",
    "options": [
      "def binary_search(arr, x):\n    mid = len(arr) // 2\n    if arr[mid] == x:\n        return mid\n    elif x < arr[mid]:\n        return binary_search(arr[:mid], x)\n    else:\n        return binary_search(arr[mid+1:], x)",
      "def binary_search(arr, x, low, high):\n    if low > high:\n        return -1\n    mid = (low + high) // 2\n    if arr[mid] == x:\n        return mid\n    elif arr[mid] > x:\n        return binary_search(arr, x, low, mid - 1)\n    else:\n        return binary_search(arr, x, mid + 1, high)",
      "def binary_search(arr, x):\n    return arr.index(x)",
      "def binary_search(arr, x, low, high):\n    return (low + high) // 2 if x in arr else -1"
    ],
    "correctAnswer": 1,
    "explanation": "Option 2 shows a correct recursive Binary Search using `low` and `high` pointers. Option 1 is close but inefficient due to slicing."
  },
  
  {
    "id": 83,
    "topic": "Searching",
    "algorithm": "Hash Table Lookup",
    "difficulty": "Medium",
    "question": "Which of the following is a correct way to search in a hash table (dictionary) in Python?",
    "options": [
      "if key in dict:\n    return dict[key]",
      "if dict.has_key(key):\n    return dict[key]",
      "if dict[key]:\n    return key",
      "dict.get(key)"
    ],
    "correctAnswer": 0,
    "explanation": "Using `key in dict` is the Pythonic and safe way to check existence before access. Option 2 uses deprecated syntax."
  },
  {
    "id": 84,
    "topic": "Searching",
    "algorithm": "Ternary Search",
    "difficulty": "Medium",
    "question": "Which of the following correctly divides the array in Ternary Search?",
    "options": [
      "mid = (low + high) // 2",
      "mid1 = low + (high - low) // 2\nmid2 = mid1 + 1",
      "mid1 = low + (high - low) // 3\nmid2 = high - (high - low) // 3",
      "mid1 = (low + high) // 3\nmid2 = 2 * mid1"
    ],
    "correctAnswer": 2,
    "explanation": "Ternary Search divides the array into three parts using `mid1 = low + (high - low)/3` and `mid2 = high - (high - low)/3`."
  }
,


    {
        "id": 61,
        "topic": "Data Structures",
        "algorithm": "Linked List",
        "difficulty": "Easy",
        "question": "What is the basic idea of Linked List?",
        "options": [
            "Linked List compares and processes elements step by step",
            "It uses dynamic programming",
            "It uses hashing",
            "It uses recursion with memoization"
        ],
        "correctAnswer": 0,
        "explanation": "Linked List is based on a fundamental step-by-step process, not advanced techniques like DP or hashing."
    },
    {
        "id": 62,
        "topic": "Data Structures",
        "algorithm": "Linked List",
        "difficulty": "Easy",
        "question": "What is the best case time complexity of Linked List?",
        "options": [
            "O(1)",
            "O(n)",
            "O(n log n)",
            "O(n\u00b2)"
        ],
        "correctAnswer": 1,
        "explanation": "In the best case, Linked List can often achieve O(n), especially when data is already partially structured."
    },
    {
        "id": 63,
        "topic": "Data Structures",
        "algorithm": "Linked List",
        "difficulty": "Medium",
        "question": "What is the average case time complexity of Linked List?",
        "options": [
            "O(n)",
            "O(n log n)",
            "O(n\u00b2)",
            "O(log n)"
        ],
        "correctAnswer": 2,
        "explanation": "Typically, Linked List has an average case of O(n\u00b2)."
    },
    {
        "id": 64,
        "topic": "Data Structures",
        "algorithm": "Linked List",
        "difficulty": "Medium",
        "question": "Which data structure is commonly associated with Linked List?",
        "options": [
            "Array",
            "Stack",
            "Queue",
            "Tree"
        ],
        "correctAnswer": 0,
        "explanation": "Linked List usually works directly on arrays in basic implementations."
    },
    {
        "id": 65,
        "topic": "Data Structures",
        "algorithm": "Linked List",
        "difficulty": "Hard",
        "question": "What is the worst case space complexity of Linked List?",
        "options": [
            "O(1)",
            "O(log n)",
            "O(n)",
            "O(n\u00b2)"
        ],
        "correctAnswer": 0,
        "explanation": "Linked List requires O(1) extra space in the worst case."
    },
    {
        "id": 66,
        "topic": "Data Structures",
        "algorithm": "Linked List",
        "difficulty": "Hard",
        "question": "What makes Linked List less efficient compared to advanced algorithms?",
        "options": [
            "Higher time complexity",
            "More space usage",
            "Not adaptive",
            "All of the above"
        ],
        "correctAnswer": 3,
        "explanation": "Linked List is often less efficient due to multiple factors like higher time complexity, space usage, and lack of adaptability."
    },
    {
        "id": 67,
        "topic": "Data Structures",
        "algorithm": "Stack",
        "difficulty": "Easy",
        "question": "What is the basic idea of Stack?",
        "options": [
            "Stack compares and processes elements step by step",
            "It uses dynamic programming",
            "It uses hashing",
            "It uses recursion with memoization"
        ],
        "correctAnswer": 0,
        "explanation": "Stack is based on a fundamental step-by-step process, not advanced techniques like DP or hashing."
    },
    {
        "id": 68,
        "topic": "Data Structures",
        "algorithm": "Stack",
        "difficulty": "Easy",
        "question": "What is the best case time complexity of Stack?",
        "options": [
            "O(1)",
            "O(n)",
            "O(n log n)",
            "O(n\u00b2)"
        ],
        "correctAnswer": 1,
        "explanation": "In the best case, Stack can often achieve O(n), especially when data is already partially structured."
    },
    {
        "id": 69,
        "topic": "Data Structures",
        "algorithm": "Stack",
        "difficulty": "Medium",
        "question": "What is the average case time complexity of Stack?",
        "options": [
            "O(n)",
            "O(n log n)",
            "O(n\u00b2)",
            "O(log n)"
        ],
        "correctAnswer": 2,
        "explanation": "Typically, Stack has an average case of O(n\u00b2)."
    },
    {
        "id": 70,
        "topic": "Data Structures",
        "algorithm": "Stack",
        "difficulty": "Medium",
        "question": "Which data structure is commonly associated with Stack?",
        "options": [
            "Array",
            "Stack",
            "Queue",
            "Tree"
        ],
        "correctAnswer": 0,
        "explanation": "Stack usually works directly on arrays in basic implementations."
    },
    {
        "id": 71,
        "topic": "Data Structures",
        "algorithm": "Stack",
        "difficulty": "Hard",
        "question": "What is the worst case space complexity of Stack?",
        "options": [
            "O(1)",
            "O(log n)",
            "O(n)",
            "O(n\u00b2)"
        ],
        "correctAnswer": 0,
        "explanation": "Stack requires O(1) extra space in the worst case."
    },
    {
        "id": 72,
        "topic": "Data Structures",
        "algorithm": "Stack",
        "difficulty": "Hard",
        "question": "What makes Stack less efficient compared to advanced algorithms?",
        "options": [
            "Higher time complexity",
            "More space usage",
            "Not adaptive",
            "All of the above"
        ],
        "correctAnswer": 3,
        "explanation": "Stack is often less efficient due to multiple factors like higher time complexity, space usage, and lack of adaptability."
    },
    {
        "id": 73,
        "topic": "Data Structures",
        "algorithm": "Queue",
        "difficulty": "Easy",
        "question": "What is the basic idea of Queue?",
        "options": [
            "Queue compares and processes elements step by step",
            "It uses dynamic programming",
            "It uses hashing",
            "It uses recursion with memoization"
        ],
        "correctAnswer": 0,
        "explanation": "Queue is based on a fundamental step-by-step process, not advanced techniques like DP or hashing."
    },
    {
        "id": 74,
        "topic": "Data Structures",
        "algorithm": "Queue",
        "difficulty": "Easy",
        "question": "What is the best case time complexity of Queue?",
        "options": [
            "O(1)",
            "O(n)",
            "O(n log n)",
            "O(n\u00b2)"
        ],
        "correctAnswer": 1,
        "explanation": "In the best case, Queue can often achieve O(n), especially when data is already partially structured."
    },
    {
        "id": 75,
        "topic": "Data Structures",
        "algorithm": "Queue",
        "difficulty": "Medium",
        "question": "What is the average case time complexity of Queue?",
        "options": [
            "O(n)",
            "O(n log n)",
            "O(n\u00b2)",
            "O(log n)"
        ],
        "correctAnswer": 2,
        "explanation": "Typically, Queue has an average case of O(n\u00b2)."
    },
    {
        "id": 76,
        "topic": "Data Structures",
        "algorithm": "Queue",
        "difficulty": "Medium",
        "question": "Which data structure is commonly associated with Queue?",
        "options": [
            "Array",
            "Stack",
            "Queue",
            "Tree"
        ],
        "correctAnswer": 0,
        "explanation": "Queue usually works directly on arrays in basic implementations."
    },
    {
        "id": 77,
        "topic": "Data Structures",
        "algorithm": "Queue",
        "difficulty": "Hard",
        "question": "What is the worst case space complexity of Queue?",
        "options": [
            "O(1)",
            "O(log n)",
            "O(n)",
            "O(n\u00b2)"
        ],
        "correctAnswer": 0,
        "explanation": "Queue requires O(1) extra space in the worst case."
    },
    {
        "id": 78,
        "topic": "Data Structures",
        "algorithm": "Queue",
        "difficulty": "Hard",
        "question": "What makes Queue less efficient compared to advanced algorithms?",
        "options": [
            "Higher time complexity",
            "More space usage",
            "Not adaptive",
            "All of the above"
        ],
        "correctAnswer": 3,
        "explanation": "Queue is often less efficient due to multiple factors like higher time complexity, space usage, and lack of adaptability."
    },
    {
        "id": 79,
        "topic": "Data Structures",
        "algorithm": "Binary Tree",
        "difficulty": "Easy",
        "question": "What is the basic idea of Binary Tree?",
        "options": [
            "Binary Tree compares and processes elements step by step",
            "It uses dynamic programming",
            "It uses hashing",
            "It uses recursion with memoization"
        ],
        "correctAnswer": 0,
        "explanation": "Binary Tree is based on a fundamental step-by-step process, not advanced techniques like DP or hashing."
    },
    {
        "id": 80,
        "topic": "Data Structures",
        "algorithm": "Binary Tree",
        "difficulty": "Easy",
        "question": "What is the best case time complexity of Binary Tree?",
        "options": [
            "O(1)",
            "O(n)",
            "O(n log n)",
            "O(n\u00b2)"
        ],
        "correctAnswer": 1,
        "explanation": "In the best case, Binary Tree can often achieve O(n), especially when data is already partially structured."
    },
    {
        "id": 81,
        "topic": "Data Structures",
        "algorithm": "Binary Tree",
        "difficulty": "Medium",
        "question": "What is the average case time complexity of Binary Tree?",
        "options": [
            "O(n)",
            "O(n log n)",
            "O(n\u00b2)",
            "O(log n)"
        ],
        "correctAnswer": 2,
        "explanation": "Typically, Binary Tree has an average case of O(n\u00b2)."
    },
    {
        "id": 82,
        "topic": "Data Structures",
        "algorithm": "Binary Tree",
        "difficulty": "Medium",
        "question": "Which data structure is commonly associated with Binary Tree?",
        "options": [
            "Array",
            "Stack",
            "Queue",
            "Tree"
        ],
        "correctAnswer": 0,
        "explanation": "Binary Tree usually works directly on arrays in basic implementations."
    },
    {
        "id": 83,
        "topic": "Data Structures",
        "algorithm": "Binary Tree",
        "difficulty": "Hard",
        "question": "What is the worst case space complexity of Binary Tree?",
        "options": [
            "O(1)",
            "O(log n)",
            "O(n)",
            "O(n\u00b2)"
        ],
        "correctAnswer": 2,
        "explanation": "Binary Tree requires O(n) extra space in the worst case."
    },
    {
        "id": 84,
        "topic": "Data Structures",
        "algorithm": "Binary Tree",
        "difficulty": "Hard",
        "question": "What makes Binary Tree less efficient compared to advanced algorithms?",
        "options": [
            "Higher time complexity",
            "More space usage",
            "Not adaptive",
            "All of the above"
        ],
        "correctAnswer": 3,
        "explanation": "Binary Tree is often less efficient due to multiple factors like higher time complexity, space usage, and lack of adaptability."
    },
    {
        "id": 85,
        "topic": "Other Topics",
        "algorithm": "Hashing",
        "difficulty": "Easy",
        "question": "What is the main purpose of hashing?",
        "options": [
            "Store data sequentially",
            "Map data to fixed-size values for fast access",
            "Sort data efficiently",
            "Compress data to smaller size"
        ],
        "correctAnswer": 1,
        "explanation": "Hashing maps arbitrary-sized data to fixed-size values (hash codes) to allow fast insertion, deletion, and lookup."
    },
    {
        "id": 86,
        "topic": "Other Topics",
        "algorithm": "Hashing",
        "difficulty": "Easy",
        "question": "Which data structure commonly uses hashing for fast access?",
        "options": [
            "Array",
            "Linked List",
            "Hash Table",
            "Stack"
        ],
        "correctAnswer": 2,
        "explanation": "Hash tables use hashing to map keys to indices, allowing O(1) average-time lookup."
    },
    {
        "id": 87,
        "topic": "Other Topics",
        "algorithm": "Hashing",
        "difficulty": "Medium",
        "question": "Which of the following is a collision resolution technique in hashing?",
        "options": [
            "Binary Search",
            "Chaining",
            "Heapify",
            "Merge Sort"
        ],
        "correctAnswer": 1,
        "explanation": "Chaining is used to store multiple elements at the same index in case of a collision."
    },
    {
        "id": 88,
        "topic": "Other Topics",
        "algorithm": "Hashing",
        "difficulty": "Medium",
        "question": "What is a hash function?",
        "options": [
            "A function that sorts elements",
            "A function that maps keys to integer indices",
            "A function that compares two arrays",
            "A function that computes factorial"
        ],
        "correctAnswer": 1,
        "explanation": "A hash function converts a key into an integer index for storage in a hash table."
    },
    {
        "id": 89,
        "topic": "Other Topics",
        "algorithm": "Hashing",
        "difficulty": "Hard",
        "question": "Why is the choice of a good hash function important?",
        "options": [
            "To ensure fewer collisions and uniform distribution",
            "To make the table smaller",
            "To sort the keys automatically",
            "To compress data efficiently"
        ],
        "correctAnswer": 0,
        "explanation": "A good hash function reduces collisions and distributes keys uniformly, ensuring O(1) performance."
    },
    {
        "id": 90,
        "topic": "Other Topics",
        "algorithm": "Hashing",
        "difficulty": "Hard",
        "question": "What can happen if all keys hash to the same index?",
        "options": [
            "The hash table becomes empty",
            "The hash table degenerates into a linked list",
            "The hash table sorts automatically",
            "Nothing significant"
        ],
        "correctAnswer": 1,
        "explanation": "If all keys collide to the same index, chaining will make a long list, degrading performance to O(n)."
    },
    {
        "id": 91,
        "topic": "Other Topics",
        "algorithm": "Hash Table",
        "difficulty": "Easy",
        "question": "What is stored at each index of a hash table?",
        "options": [
            "Elements or key-value pairs",
            "Only keys",
            "Only indices",
            "Sorted arrays"
        ],
        "correctAnswer": 0,
        "explanation": "Each index of a hash table stores elements, usually as key-value pairs."
    },
    {
        "id": 92,
        "topic": "Other Topics",
        "algorithm": "Hash Table",
        "difficulty": "Easy",
        "question": "Hash tables provide which average time complexity for search operations?",
        "options": [
            "O(n)",
            "O(log n)",
            "O(1)",
            "O(n log n)"
        ],
        "correctAnswer": 2,
        "explanation": "Search in hash tables is O(1) on average due to direct mapping by hash codes."
    },
    {
        "id": 93,
        "topic": "Other Topics",
        "algorithm": "Hash Table",
        "difficulty": "Medium",
        "question": "Which of the following affects hash table performance?",
        "options": [
            "Load factor",
            "Hash function quality",
            "Collision resolution technique",
            "All of the above"
        ],
        "correctAnswer": 3,
        "explanation": "Load factor, hash function, and collision resolution all impact hash table efficiency."
    },
    {
        "id": 94,
        "topic": "Other Topics",
        "algorithm": "Hash Table",
        "difficulty": "Medium",
        "question": "What happens when the load factor exceeds a threshold in a hash table?",
        "options": [
            "The table resizes",
            "Elements are deleted",
            "The hash function changes",
            "Nothing"
        ],
        "correctAnswer": 0,
        "explanation": "When the load factor is high, the table is resized to reduce collisions and maintain O(1) performance."
    },
    {
        "id": 95,
        "topic": "Other Topics",
        "algorithm": "Hash Table",
        "difficulty": "Hard",
        "question": "Worst-case time complexity of search in a hash table using chaining is?",
        "options": [
            "O(1)",
            "O(log n)",
            "O(n)",
            "O(n log n)"
        ],
        "correctAnswer": 2,
        "explanation": "In the worst case, all keys hash to the same index, forming a list of size n, giving O(n) search time."
    },
    {
        "id": 96,
        "topic": "Other Topics",
        "algorithm": "Hash Table",
        "difficulty": "Hard",
        "question": "Which of the following is NOT a valid collision resolution technique?",
        "options": [
            "Chaining",
            "Linear probing",
            "Heap sort",
            "Double hashing"
        ],
        "correctAnswer": 2,
        "explanation": "Heap sort is unrelated to collision resolution in hash tables."
    },
    {
        "id": 97,
        "topic": "Other Topics",
        "algorithm": "chainingHash",
        "difficulty": "Easy",
        "question": "In chaining, where are colliding elements stored?",
        "options": [
            "In a separate hash table",
            "In a linked list at the same index",
            "In a stack",
            "In an array sorted by key"
        ],
        "correctAnswer": 1,
        "explanation": "Chaining stores multiple colliding elements in a linked list at the same table index."
    },
    {
        "id": 98,
        "topic": "Other Topics",
        "algorithm": "chainingHash",
        "difficulty": "Easy",
        "question": "Which data structure is commonly used in chaining?",
        "options": [
            "Queue",
            "Linked List",
            "Binary Tree",
            "Heap"
        ],
        "correctAnswer": 1,
        "explanation": "Linked lists are used at each index to store multiple colliding elements."
    },
    {
        "id": 99,
        "topic": "Other Topics",
        "algorithm": "chainingHash",
        "difficulty": "Medium",
        "question": "What is the average search complexity in chaining with a low load factor?",
        "options": [
            "O(1)",
            "O(log n)",
            "O(n)",
            "O(n log n)"
        ],
        "correctAnswer": 0,
        "explanation": "With a low load factor, most indices have very few elements, giving O(1) average search time."
    },
    {
        "id": 100,
        "topic": "Other Topics",
        "algorithm": "chainingHash",
        "difficulty": "Medium",
        "question": "If a hash table uses chaining and all keys hash to the same index, what is the worst-case search time?",
        "options": [
            "O(1)",
            "O(log n)",
            "O(n)",
            "O(n^2)"
        ],
        "correctAnswer": 2,
        "explanation": "All keys in one linked list give O(n) search in the worst case."
    },
    {
        "id": 101,
        "topic": "Other Topics",
        "algorithm": "chainingHash",
        "difficulty": "Hard",
        "question": "Which of the following improves search efficiency in chaining?",
        "options": [
            "Using balanced BSTs instead of linked lists",
            "Increasing table size",
            "Reducing load factor",
            "All of the above"
        ],
        "correctAnswer": 3,
        "explanation": "All options help: BSTs improve lookup, larger table reduces collisions, lower load factor reduces chain length."
    },
    {
        "id": 102,
        "topic": "Other Topics",
        "algorithm": "chainingHash",
        "difficulty": "Hard",
        "question": "Which is a disadvantage of chaining?",
        "options": [
            "Wastes memory due to pointers",
            "Cannot handle collisions",
            "Always slower than open addressing",
            "Does not allow deletion"
        ],
        "correctAnswer": 0,
        "explanation": "Chaining requires extra memory for pointers in linked lists, which is a trade-off for simpler collision handling."
    },
    {
        "id": 103,
        "topic": "Other Topics",
        "algorithm": "Open Addressing",
        "difficulty": "Easy",
        "question": "In open addressing, where is a colliding element stored?",
        "options": [
            "In a linked list",
            "In another empty table slot",
            "At the same index",
            "In a separate array"
        ],
        "correctAnswer": 1,
        "explanation": "Open addressing finds another empty slot in the table to store the colliding element."
    },
    {
        "id": 104,
        "topic": "Other Topics",
        "algorithm": "Open Addressing",
        "difficulty": "Easy",
        "question": "Which is NOT an open addressing method?",
        "options": [
            "Linear probing",
            "Quadratic probing",
            "Double hashing",
            "Chaining"
        ],
        "correctAnswer": 3,
        "explanation": "Chaining is a separate collision handling technique, not open addressing."
    },
    {
        "id": 105,
        "topic": "Other Topics",
        "algorithm": "Open Addressing",
        "difficulty": "Medium",
        "question": "What is primary clustering in open addressing?",
        "options": [
            "When multiple elements hash to the same index",
            "When clusters of occupied slots form, slowing insert/search",
            "When the hash table resizes",
            "When hash function fails"
        ],
        "correctAnswer": 1,
        "explanation": "Primary clustering occurs when clusters of consecutive occupied slots form, increasing probe length."
    },
    {
        "id": 106,
        "topic": "Other Topics",
        "algorithm": "Open Addressing",
        "difficulty": "Medium",
        "question": "What is the average search complexity of open addressing with low load factor?",
        "options": [
            "O(n)",
            "O(log n)",
            "O(1)",
            "O(n log n)"
        ],
        "correctAnswer": 2,
        "explanation": "With a low load factor, most searches find their element quickly, giving O(1) average complexity."
    },
    {
        "id": 107,
        "topic": "Other Topics",
        "algorithm": "Open Addressing",
        "difficulty": "Hard",
        "question": "What is the worst-case search time in open addressing?",
        "options": [
            "O(1)",
            "O(log n)",
            "O(n)",
            "O(n log n)"
        ],
        "correctAnswer": 2,
        "explanation": "If all elements form a cluster or table is nearly full, worst-case search can take O(n)."
    },
    {
        "id": 108,
        "topic": "Other Topics",
        "algorithm": "Open Addressing",
        "difficulty": "Hard",
        "question": "Which of these helps reduce clustering in open addressing?",
        "options": [
            "Linear probing",
            "Quadratic probing or double hashing",
            "Always resizing table",
            "Using linked lists"
        ],
        "correctAnswer": 1,
        "explanation": "Quadratic probing and double hashing reduce clustering by spreading keys more uniformly."
    },
    {
        "id": 109,
        "topic": "Other Topics",
        "algorithm": "Rolling Hash",
        "difficulty": "Easy",
        "question": "Rolling hash is used primarily in which type of algorithms?",
        "options": [
            "Sorting algorithms",
            "Substring search algorithms",
            "Graph traversal algorithms",
            "Dynamic programming"
        ],
        "correctAnswer": 1,
        "explanation": "Rolling hash allows fast substring search, used in algorithms like Rabin-Karp."
    },
    {
        "id": 110,
        "topic": "Other Topics",
        "algorithm": "Rolling Hash",
        "difficulty": "Easy",
        "question": "What is the advantage of rolling hash over normal hash in string matching?",
        "options": [
            "Faster hash recomputation when sliding window",
            "No collisions",
            "Uses less memory",
            "Automatically sorts substrings"
        ],
        "correctAnswer": 0,
        "explanation": "Rolling hash lets you compute the next hash by updating the previous one, avoiding full recomputation."
    },
    {
        "id": 111,
        "topic": "Other Topics",
        "algorithm": "Rolling Hash",
        "difficulty": "Medium",
        "question": "Which problem is solved efficiently using rolling hash?",
        "options": [
            "Merge Sort",
            "Rabin-Karp string search",
            "DFS on trees",
            "Binary search"
        ],
        "correctAnswer": 1,
        "explanation": "Rabin-Karp uses rolling hash for fast substring matching."
    },
    {
        "id": 112,
        "topic": "Other Topics",
        "algorithm": "Rolling Hash",
        "difficulty": "Medium",
        "question": "What is the time complexity of substring search using Rabin-Karp with rolling hash?",
        "options": [
            "O(N  M)",
            "O(N + M)",
            "O(N log M)",
            "O(1)"
        ],
        "correctAnswer": 1,
        "explanation": "With rolling hash, Rabin-Karp runs in O(N + M) average time for pattern matching."
    },
    {
        "id": 113,
        "topic": "Other Topics",
        "algorithm": "Rolling Hash",
        "difficulty": "Hard",
        "question": "Which property of rolling hash is critical for efficient substring matching?",
        "options": [
            "Incremental hash computation",
            "No collisions",
            "Sorting substrings",
            "Dynamic memory allocation"
        ],
        "correctAnswer": 0,
        "explanation": "Incremental update of hash values enables efficient sliding window substring search."
    },
    {
        "id": 114,
        "topic": "Other Topics",
        "algorithm": "Rolling Hash",
        "difficulty": "Hard",
        "question": "Which problem arises if the rolling hash is not designed carefully?",
        "options": [
            "Increased memory usage",
            "Hash collisions causing false positives",
            "Slower sorting",
            "Unable to store keys"
        ],
        "correctAnswer": 1,
        "explanation": "Poor hash design can cause collisions, resulting in false matches during substring search."
    },
    {
        "id": 115,
        "topic": "Other Topics",
        "algorithm": "Hash - Applications",
        "difficulty": "Easy",
        "question": "Which of the following is a common use of hashing?",
        "options": [
            "Sorting arrays",
            "Finding duplicates",
            "DFS traversal",
            "Dynamic programming"
        ],
        "correctAnswer": 1,
        "explanation": "Hashing is often used to find duplicates efficiently using sets or hash maps."
    },
    {
        "id": 116,
        "topic": "Other Topics",
        "algorithm": "Hash - Applications",
        "difficulty": "Easy",
        "question": "Which data structure is typically implemented using hashing?",
        "options": [
            "Queue",
            "Stack",
            "Map or Dictionary",
            "Binary Tree"
        ],
        "correctAnswer": 2,
        "explanation": "Maps or dictionaries use hashing to map keys to values with O(1) access."
    },
    {
        "id": 117,
        "topic": "Other Topics",
        "algorithm": "Hash - Applications",
        "difficulty": "Medium",
        "question": "Hashing is often used in which common algorithmic problem?",
        "options": [
            "Two-sum problem",
            "Merge sort",
            "Binary search",
            "DFS traversal"
        ],
        "correctAnswer": 0,
        "explanation": "Hashing allows checking complements efficiently, solving the two-sum problem in O(n) time."
    },
    {
        "id": 118,
        "topic": "Other Topics",
        "algorithm": "Hash - Applications",
        "difficulty": "Medium",
        "question": "Which application benefits from counting frequencies using hashing?",
        "options": [
            "Finding duplicates",
            "Word frequency in documents",
            "Histogram generation",
            "All of the above"
        ],
        "correctAnswer": 3,
        "explanation": "Hashing can efficiently count frequencies for all these applications."
    },
    {
        "id": 119,
        "topic": "Other Topics",
        "algorithm": "Hash - Applications",
        "difficulty": "Hard",
        "question": "Which problem requires careful hash function design to avoid collisions?",
        "options": [
            "Counting frequencies",
            "Two-sum problem",
            "Substring matching",
            "All of the above"
        ],
        "correctAnswer": 3,
        "explanation": "All listed problems can be impacted by hash collisions, requiring good hash functions."
    },
    {
        "id": 120,
        "topic": "Other Topics",
        "algorithm": "Hash - Applications",
        "difficulty": "Hard",
        "question": "Which of these algorithms heavily rely on hashing?",
        "options": [
            "Rabin-Karp string search",
            "Frequency counter in data streams",
            "Hash-based caches and memoization",
            "All of the above"
        ],
        "correctAnswer": 3,
        "explanation": "Hashing is crucial in substring search, frequency counting, and cache/memoization implementations."
    },
    {
    "id": 121,
    "topic": "Other Topics",
    "algorithm": "Branch & Bound: Knapsack 01",
    "difficulty": "Easy",
    "question": "What is the basic concept of the 0/1 Knapsack problem?",
    "options": [
      "Selecting items with binary choice (take or leave) to maximize value within weight limit",
      "Sorting items by weight",
      "Finding the shortest path in a graph",
      "Minimizing the number of items"
    ],
    "correctAnswer": 0,
    "explanation": "The 0/1 Knapsack problem involves making binary (yes/no) decisions for each item to maximize total value while respecting weight constraints."
    },
    {
        "id": 122,
        "topic": "Other Topics",
        "algorithm": "Branch & Bound: Knapsack 01",
        "difficulty": "Easy",
        "question": "What is the role of bounding in the Knapsack problem?",
        "options": [
        "To estimate the best possible value achievable in a subtree",
        "To sort items by weight",
        "To count the number of items",
        "To calculate the minimum weight"
        ],
        "correctAnswer": 0,
        "explanation": "Bounding functions estimate the maximum possible value achievable in a branch, helping prune unpromising paths."
    },
    {
        "id": 123,
        "topic": "Other Topics",
        "algorithm": "Branch & Bound: Knapsack 01",
        "difficulty": "Medium",
        "question": "How does Branch & Bound improve upon brute force for the Knapsack problem?",
        "options": [
        "By pruning branches that cannot lead to better solutions",
        "By sorting items first",
        "By using dynamic programming",
        "By using greedy selection"
        ],
        "correctAnswer": 0,
        "explanation": "Branch & Bound improves efficiency by eliminating branches that cannot produce better solutions than the current best."
    },
    {
        "id": 124,
        "topic": "Other Topics",
        "algorithm": "Branch & Bound: Knapsack 01",
        "difficulty": "Medium",
        "question": "What is the most effective bounding function for the Knapsack problem?",
        "options": [
        "Fractional knapsack value",
        "Total weight",
        "Item count",
        "Random estimation"
        ],
        "correctAnswer": 0,
        "explanation": "The fractional knapsack solution provides an optimistic estimate of the best possible value achievable in a branch."
    },
    {
        "id": 125,
        "topic": "Other Topics",
        "algorithm": "Branch & Bound: Knapsack 01",
        "difficulty": "Hard",
        "question": "What is the worst-case time complexity of Branch & Bound for Knapsack?",
        "options": [
        "O(2\u207f)",
        "O(n log n)",
        "O(n)",
        "O(n\u00b2)"
        ],
        "correctAnswer": 0,
        "explanation": "In the worst case, Branch & Bound might still need to explore all possible combinations, leading to O(2\u207f)."
    },
    {
        "id": 126,
        "topic": "Other Topics",
        "algorithm": "Branch & Bound: Knapsack 01",
        "difficulty": "Hard",
        "question": "How does the ordering of items affect Knapsack Branch & Bound efficiency?",
        "options": [
        "Sorting by value/weight ratio can improve pruning effectiveness",
        "Order doesn't matter",
        "Random ordering is best",
        "Sorting by weight only is optimal"
        ],
        "correctAnswer": 0,
        "explanation": "Sorting items by value/weight ratio can help find good solutions early, enabling more effective pruning."
    },
    {
        "id": 127,
        "topic": "Other Topics",
        "algorithm": "Branch & Bound: Traveling Salesman",
        "difficulty": "Easy",
        "question": "What is the basic idea of TSP Branch & Bound?",
        "options": [
        "Finding the shortest tour visiting all cities exactly once",
        "Finding the longest path",
        "Finding all possible paths",
        "Finding multiple tours"
        ],
        "correctAnswer": 0,
        "explanation": "TSP aims to find the minimum cost tour that visits each city exactly once and returns to the starting city."
    },
    {
        "id": 128,
        "topic": "Other Topics",
        "algorithm": "Branch & Bound: Traveling Salesman",
        "difficulty": "Easy",
        "question": "What is a lower bound in TSP Branch & Bound?",
        "options": [
        "Minimum possible cost of completing a partial tour",
        "Maximum possible tour length",
        "Number of cities",
        "Average distance between cities"
        ],
        "correctAnswer": 0,
        "explanation": "A lower bound estimates the minimum possible cost to complete a partial tour, used for pruning unpromising branches."
    },
    {
        "id": 129,
        "topic": "Other Topics",
        "algorithm": "Branch & Bound: Traveling Salesman",
        "difficulty": "Medium",
        "question": "What is the role of the reduced cost matrix in TSP?",
        "options": [
        "To provide better lower bounds for partial solutions",
        "To increase the tour length",
        "To count cities",
        "To maximize distance"
        ],
        "correctAnswer": 0,
        "explanation": "The reduced cost matrix helps calculate tighter lower bounds, making branch pruning more effective."
    },
    {
        "id": 130,
        "topic": "Other Topics",
        "algorithm": "Branch & Bound: Traveling Salesman",
        "difficulty": "Medium",
        "question": "How are subtours eliminated in TSP Branch & Bound?",
        "options": [
        "By maintaining a path and checking for cycles",
        "By increasing distances",
        "By removing cities",
        "By adding random edges"
        ],
        "correctAnswer": 0,
        "explanation": "The algorithm maintains a valid path and ensures no cycles are formed until the final edge of the tour."
    },
    {
        "id": 131,
        "topic": "Other Topics",
        "algorithm": "Branch & Bound: Traveling Salesman",
        "difficulty": "Hard",
        "question": "What is the most effective branching strategy for TSP?",
        "options": [
        "Selecting cities based on minimum cost edges",
        "Random selection",
        "Maximum cost edges",
        "Middle edges"
        ],
        "correctAnswer": 0,
        "explanation": "Choosing cities connected by minimum cost edges first often leads to better solutions earlier."
    },
    {
        "id": 132,
        "topic": "Other Topics",
        "algorithm": "Branch & Bound: Traveling Salesman",
        "difficulty": "Hard",
        "question": "What makes TSP particularly challenging for Branch & Bound?",
        "options": [
        "The combination of tour constraints and optimization",
        "The number of cities",
        "The distance calculation",
        "The path finding"
        ],
        "correctAnswer": 0,
        "explanation": "TSP combines the challenges of maintaining valid tours while optimizing the total cost, making effective pruning crucial."
    },
    {
        "id": 133,
        "topic": "Other Topics",
        "algorithm": "Game Search: Minimax",
        "difficulty": "Easy",
        "question": "What is the fundamental principle of the Minimax algorithm?",
        "options": [
        "Alternating between maximizing and minimizing player moves",
        "Always choosing random moves",
        "Always selecting the first available move",
        "Ignoring opponent moves"
        ],
        "correctAnswer": 0,
        "explanation": "Minimax alternates between maximizing the current player's position and minimizing the opponent's opportunities."
    },
    {
        "id": 134,
        "topic": "Other Topics",
        "algorithm": "Game Search: Minimax",
        "difficulty": "Easy",
        "question": "What type of games is Minimax best suited for?",
        "options": [
        "Two-player, zero-sum games with perfect information",
        "Single-player games",
        "Games of chance",
        "Multiplayer games"
        ],
        "correctAnswer": 0,
        "explanation": "Minimax works best for games like chess or tic-tac-toe where two players compete and all information is visible."
    },
    {
        "id": 135,
        "topic": "Other Topics",
        "algorithm": "Game Search: Minimax",
        "difficulty": "Medium",
        "question": "How does Minimax handle game tree depth limitations?",
        "options": [
        "Using evaluation functions at cutoff depth",
        "Ignoring deeper nodes",
        "Random selection",
        "Continuing indefinitely"
        ],
        "correctAnswer": 0,
        "explanation": "When the search can't reach terminal positions, Minimax uses heuristic evaluation functions to estimate position value."
    },
    {
        "id": 136,
        "topic": "Other Topics",
        "algorithm": "Game Search: Minimax",
        "difficulty": "Medium",
        "question": "What determines the effectiveness of a Minimax evaluation function?",
        "options": [
        "Its ability to accurately estimate position strength",
        "The speed of calculation",
        "The number of moves considered",
        "The game tree depth"
        ],
        "correctAnswer": 0,
        "explanation": "A good evaluation function must provide reliable estimates of position strength to make effective decisions."
    },
    {
        "id": 137,
        "topic": "Other Topics",
        "algorithm": "Game Search: Minimax",
        "difficulty": "Hard",
        "question": "What is the time complexity of Minimax without pruning?",
        "options": [
        "O(b\u1d48) where b is branching factor and d is depth",
        "O(n)",
        "O(log n)",
        "O(n\u00b2)"
        ],
        "correctAnswer": 0,
        "explanation": "Minimax must explore all possible moves to a given depth, leading to exponential time complexity."
    },
    {
        "id": 138,
        "topic": "Other Topics",
        "algorithm": "Game Search: Minimax",
        "difficulty": "Hard",
        "question": "How does Minimax handle transpositions in the game tree?",
        "options": [
        "Using a transposition table to cache results",
        "Recalculating every position",
        "Ignoring repeated positions",
        "Random selection"
        ],
        "correctAnswer": 0,
        "explanation": "Transposition tables store previously evaluated positions to avoid redundant calculations."
    },
    {
        "id": 139,
        "topic": "Other Topics",
        "algorithm": "Game Search: Alpha-Beta Pruning",
        "difficulty": "Easy",
        "question": "What is the main purpose of Alpha-Beta pruning?",
        "options": [
        "To reduce the number of nodes evaluated by Minimax",
        "To increase search depth",
        "To evaluate more nodes",
        "To randomize search"
        ],
        "correctAnswer": 0,
        "explanation": "Alpha-Beta pruning improves Minimax efficiency by skipping evaluation of irrelevant branches."
    },
    {
        "id": 140,
        "topic": "Other Topics",
        "algorithm": "Game Search: Alpha-Beta Pruning",
        "difficulty": "Easy",
        "question": "What do Alpha and Beta values represent?",
        "options": [
        "Best already explored alternatives for both players",
        "Random values",
        "Node depths",
        "Number of moves"
        ],
        "correctAnswer": 0,
        "explanation": "Alpha represents the best value for the maximizing player, Beta for the minimizing player."
    },
    {
        "id": 141,
        "topic": "Other Topics",
        "algorithm": "Game Search: Alpha-Beta Pruning",
        "difficulty": "Medium",
        "question": "How does move ordering affect Alpha-Beta efficiency?",
        "options": [
        "Good move ordering increases pruning opportunities",
        "Move order doesn't matter",
        "Random ordering is best",
        "Worst moves should be first"
        ],
        "correctAnswer": 0,
        "explanation": "Examining better moves first increases the likelihood of pruning subsequent branches."
    },
    {
        "id": 142,
        "topic": "Other Topics",
        "algorithm": "Game Search: Alpha-Beta Pruning",
        "difficulty": "Medium",
        "question": "What is a null window search in Alpha-Beta?",
        "options": [
        "A search with Alpha and Beta values very close together",
        "A search with no pruning",
        "A random search",
        "A complete tree search"
        ],
        "correctAnswer": 0,
        "explanation": "Null window searches are used to efficiently determine if a position is above or below a specific value."
    },
    {
        "id": 143,
        "topic": "Other Topics",
        "algorithm": "Game Search: Alpha-Beta Pruning",
        "difficulty": "Hard",
        "question": "What is the best-case time complexity of Alpha-Beta?",
        "options": [
        "O(b\u1d48/\u00b2) where b is branching factor and d is depth",
        "O(b\u1d48)",
        "O(n)",
        "O(log n)"
        ],
        "correctAnswer": 0,
        "explanation": "With perfect move ordering, Alpha-Beta can reduce the effective branching factor by roughly its square root."
    },
    {
        "id": 144,
        "topic": "Other Topics",
        "algorithm": "Game Search: Alpha-Beta Pruning",
        "difficulty": "Hard",
        "question": "How can iterative deepening improve Alpha-Beta pruning?",
        "options": [
        "By providing move ordering information for deeper searches",
        "By reducing search depth",
        "By increasing branching factor",
        "By randomizing search"
        ],
        "correctAnswer": 0,
        "explanation": "Results from shallower searches can guide move ordering in deeper searches, improving pruning efficiency."
    },
    {
        "id": 145,
        "topic": "Other Topics",
        "algorithm": "Game Search: Expectimax",
        "difficulty": "Easy",
        "question": "What type of games is Expectimax designed for?",
        "options": [
        "Games with chance elements or uncertainty",
        "Perfect information games",
        "Two-player games only",
        "Single-player games"
        ],
        "correctAnswer": 0,
        "explanation": "Expectimax handles games where some outcomes are determined by chance or probability."
    },
    {
        "id": 146,
        "topic": "Other Topics",
        "algorithm": "Game Search: Expectimax",
        "difficulty": "Easy",
        "question": "How does Expectimax differ from Minimax?",
        "options": [
        "It uses probability-weighted averages instead of minimizing",
        "It searches deeper",
        "It uses no heuristics",
        "It's always faster"
        ],
        "correctAnswer": 0,
        "explanation": "Expectimax accounts for chance events by calculating expected values rather than assuming optimal opponent play."
    },
    {
        "id": 147,
        "topic": "Other Topics",
        "algorithm": "Game Search: Expectimax",
        "difficulty": "Medium",
        "question": "How are chance nodes handled in Expectimax?",
        "options": [
        "By computing weighted averages of all possible outcomes",
        "By choosing the highest value",
        "By choosing the lowest value",
        "By random selection"
        ],
        "correctAnswer": 0,
        "explanation": "Chance nodes compute the expected value by weighing each possible outcome by its probability."
    },
    {
        "id": 148,
        "topic": "Other Topics",
        "algorithm": "Game Search: Expectimax",
        "difficulty": "Medium",
        "question": "What is the impact of depth on Expectimax computational cost?",
        "options": [
        "It grows exponentially with both branching factor and chance outcomes",
        "It's constant",
        "It grows linearly",
        "It decreases with depth"
        ],
        "correctAnswer": 0,
        "explanation": "Each level of depth multiplies the computation by both the branching factor and number of chance outcomes."
    },
    {
        "id": 149,
        "topic": "Other Topics",
        "algorithm": "Game Search: Expectimax",
        "difficulty": "Hard",
        "question": "Why can't alpha-beta pruning be fully applied to Expectimax?",
        "options": [
        "Because chance nodes must consider all outcomes",
        "Because it's not needed",
        "Because it makes it slower",
        "Because it's too complex"
        ],
        "correctAnswer": 0,
        "explanation": "Chance nodes must evaluate all possibilities to compute the correct expected value, preventing full pruning."
    },
    {
        "id": 150,
        "topic": "Other Topics",
        "algorithm": "Game Search: Expectimax",
        "difficulty": "Hard",
        "question": "How can Expectimax be optimized for practical use?",
        "options": [
        "By pruning extremely unlikely or low-impact outcomes",
        "By ignoring probabilities",
        "By reducing depth",
        "By increasing branching"
        ],
        "correctAnswer": 0,
        "explanation": "Practical implementations often ignore outcomes with very low probability or minimal impact on the expected value."
    },
    {
        "id": 151,
        "topic": "Other Topics",
        "algorithm": "Game Search: Monte Carlo Tree Search",
        "difficulty": "Easy",
        "question": "What is the basic idea of Monte Carlo Tree Search (MCTS)?",
        "options": [
        "Using random simulations to evaluate positions",
        "Calculating exact values",
        "Following fixed strategies",
        "Ignoring tree structure"
        ],
        "correctAnswer": 0,
        "explanation": "MCTS uses random playouts to estimate position value through statistical sampling."
    },
    {
        "id": 152,
        "topic": "Other Topics",
        "algorithm": "Game Search: Monte Carlo Tree Search",
        "difficulty": "Easy",
        "question": "What are the four main steps of MCTS?",
        "options": [
        "Selection, Expansion, Simulation, Backpropagation",
        "Search, Evaluate, Update, Repeat",
        "Choose, Play, Win, Lose",
        "Start, Middle, End, Reset"
        ],
        "correctAnswer": 0,
        "explanation": "These four steps form the core MCTS algorithm cycle, balancing exploration and exploitation."
    },
    {
        "id": 153,
        "topic": "Other Topics",
        "algorithm": "Game Search: Monte Carlo Tree Search",
        "difficulty": "Medium",
        "question": "What is the role of UCT in MCTS?",
        "options": [
        "Balancing exploration and exploitation",
        "Speeding up simulations",
        "Reducing memory usage",
        "Simplifying the tree"
        ],
        "correctAnswer": 0,
        "explanation": "Upper Confidence bounds for Trees (UCT) helps balance between exploring new nodes and exploiting known good moves."
    },
    {
        "id": 154,
        "topic": "Other Topics",
        "algorithm": "Game Search: Monte Carlo Tree Search",
        "difficulty": "Medium",
        "question": "How does MCTS handle large branching factors?",
        "options": [
        "By gradually building the tree through sampling",
        "By exploring all branches",
        "By ignoring some moves",
        "By random selection"
        ],
        "correctAnswer": 0,
        "explanation": "MCTS manages large branching factors by focusing resources on promising branches identified through sampling."
    },
    {
        "id": 155,
        "topic": "GOther Topics",
        "algorithm": "Game Search: Monte Carlo Tree Search",
        "difficulty": "Hard",
        "question": "What determines the quality of MCTS playouts?",
        "options": [
        "The balance between speed and simulation accuracy",
        "The number of nodes",
        "The tree depth",
        "The branching factor"
        ],
        "correctAnswer": 0,
        "explanation": "Good playouts must balance quick execution with reasonable approximation of actual game play."
    },
    {
        "id": 156,
        "topic": "Other Topics",
        "algorithm": "Game Search: Monte Carlo Tree Search",
        "difficulty": "Hard",
        "question": "How can MCTS be parallelized effectively?",
        "options": [
        "By running multiple independent trees or parallel playouts",
        "It cannot be parallelized",
        "By splitting the game board",
        "By reducing search depth"
        ],
        "correctAnswer": 0,
        "explanation": "MCTS can be parallelized through root parallelization, tree parallelization, or leaf parallelization."
    },    
    {
        "id": 157,
        "topic": "Paradigms",
        "algorithm": "Backtracking",
        "difficulty": "Easy",
        "question": "Which of the following best describes backtracking?",
        "options": [
        "Trying all possible solutions without undoing choices",
        "Systematically exploring all solutions and undoing invalid ones",
        "Choosing the best solution at each step",
        "Dividing a problem into subproblems"
        ],
        "correctAnswer": 1,
        "explanation": "Backtracking systematically explores possible solutions and undoes choices when they lead to dead ends."
    },
    {
        "id": 158,
        "topic": "Paradigms",
        "algorithm": "Backtracking",
        "difficulty": "Easy",
        "question": "Which of these is a common application of backtracking?",
        "options": [
        "N-Queens Problem",
        "Binary Search",
        "Merge Sort",
        "Dijkstra's Algorithm"
        ],
        "correctAnswer": 0,
        "explanation": "The N-Queens problem is a classic backtracking example."
    },
    {
        "id": 159,
        "topic": "Paradigms",
        "algorithm": "Backtracking",
        "difficulty": "Medium",
        "question": "Which data structure is most closely associated with backtracking?",
        "options": [
        "Queue",
        "Stack",
        "Heap",
        "Graph"
        ],
        "correctAnswer": 1,
        "explanation": "Backtracking often uses the call stack or an explicit stack to manage choices."
    },
    {
        "id": 160,
        "topic": "Paradigms",
        "algorithm": "Backtracking",
        "difficulty": "Medium",
        "question": "When does backtracking stop exploring a path?",
        "options": [
        "When a partial solution is invalid",
        "When the algorithm has tried all possible options",
        "When it finds a greedy solution",
        "After a fixed number of iterations"
        ],
        "correctAnswer": 0,
        "explanation": "Backtracking stops exploring a path as soon as the partial solution becomes invalid."
    },
    {
        "id": 161,
        "topic": "Paradigms",
        "algorithm": "Backtracking",
        "difficulty": "Hard",
        "question": "What is the worst-case time complexity of backtracking algorithms like N-Queens?",
        "options": [
        "O(N^2)",
        "O(N!)",
        "O(log N)",
        "O(2^N)"
        ],
        "correctAnswer": 1,
        "explanation": "The N-Queens backtracking solution can explore O(N!) possibilities."
    },
    {
        "id": 162,
        "topic": "Paradigms",
        "algorithm": "Backtracking",
        "difficulty": "Hard",
        "question": "Which optimization helps improve the efficiency of backtracking?",
        "options": [
        "Memoization",
        "Pruning invalid paths early",
        "Random guessing",
        "Greedy selection"
        ],
        "correctAnswer": 1,
        "explanation": "Pruning reduces the number of paths explored by eliminating invalid ones early."
    },

    {
        "id": 163,
        "topic": "Paradigms",
        "algorithm": "Backtracking : N-Queens",
        "difficulty": "Easy",
        "question": "What is the objective of the N-Queens problem?",
        "options": [
        "Place queens randomly",
        "Place N queens so that no two attack each other",
        "Sort queens by size",
        "Maximize queen moves"
        ],
        "correctAnswer": 1,
        "explanation": "The goal is to place N queens on an NN chessboard such that no two queens attack each other."
    },
    {
        "id": 164,
        "topic": "Paradigms",
        "algorithm": "Backtracking : N-Queens",
        "difficulty": "Easy",
        "question": "What is the board size in the 8-Queens problem?",
        "options": [
        "4x4",
        "6x6",
        "8x8",
        "10x10"
        ],
        "correctAnswer": 2,
        "explanation": "The 8-Queens problem uses an 88 chessboard."
    },
    {
        "id": 165,
        "topic": "Paradigms",
        "algorithm": "Backtracking : N-Queens",
        "difficulty": "Medium",
        "question": "Which algorithmic paradigm is most suitable for N-Queens?",
        "options": [
        "Greedy",
        "Dynamic Programming",
        "Backtracking",
        "Divide and Conquer"
        ],
        "correctAnswer": 2,
        "explanation": "Backtracking is the primary technique used to solve N-Queens."
    },
    {
        "id": 166,
        "topic": "Paradigms",
        "algorithm": "Backtracking : N-Queens",
        "difficulty": "Medium",
        "question": "What strategy is used to place queens in N-Queens with backtracking?",
        "options": [
        "Placing queens row by row",
        "Placing queens randomly",
        "Placing queens greedily",
        "Placing queens by sorting columns"
        ],
        "correctAnswer": 0,
        "explanation": "Backtracking places queens row by row and backtracks on conflicts."
    },
    {
        "id": 167,
        "topic": "Paradigms",
        "algorithm": "Backtracking : N-Queens",
        "difficulty": "Hard",
        "question": "How many distinct solutions exist for the 8-Queens problem?",
        "options": [
        "64",
        "92",
        "128",
        "256"
        ],
        "correctAnswer": 1,
        "explanation": "There are 92 distinct solutions for the 8-Queens problem."
    },
    {
        "id": 168,
        "topic": "Paradigms",
        "algorithm": "Backtracking : N-Queens",
        "difficulty": "Hard",
        "question": "What is the asymptotic time complexity of solving N-Queens using backtracking?",
        "options": [
        "O(N!)",
        "O(N^2)",
        "O(N log N)",
        "O(2^N)"
        ],
        "correctAnswer": 0,
        "explanation": "Backtracking for N-Queens has factorial time complexity O(N!)."
    },

    {
        "id": 169,
        "topic": "Paradigms",
        "algorithm": "Backtracking : Sudoku",
        "difficulty": "Easy",
        "question": "What is the size of a standard Sudoku grid?",
        "options": [
        "6x6",
        "9x9",
        "12x12",
        "8x8"
        ],
        "correctAnswer": 1,
        "explanation": "Standard Sudoku puzzles are played on a 9x9 grid."
    },
    {
        "id": 170,
        "topic": "Paradigms",
        "algorithm": "Backtracking : Sudoku",
        "difficulty": "Easy",
        "question": "How many sub-grids are there in a standard Sudoku puzzle?",
        "options": [
        "6",
        "9",
        "12",
        "16"
        ],
        "correctAnswer": 1,
        "explanation": "A 9x9 Sudoku grid is divided into 9 smaller 3x3 sub-grids."
    },
    {
        "id": 171,
        "topic": "Paradigms",
        "algorithm": "Backtracking : Sudoku",
        "difficulty": "Medium",
        "question": "Which algorithm is most commonly used for solving Sudoku computationally?",
        "options": [
        "Greedy Algorithm",
        "Backtracking",
        "Divide and Conquer",
        "Dynamic Programming"
        ],
        "correctAnswer": 1,
        "explanation": "Backtracking is the most common method to solve Sudoku."
    },
    {
        "id": 172,
        "topic": "Paradigms",
        "algorithm": "Backtracking : Sudoku",
        "difficulty": "Medium",
        "question": "What pruning strategy is used in Sudoku solving?",
        "options": [
        "Eliminating invalid digits early",
        "Skipping entire rows",
        "Randomly guessing values",
        "Sorting the digits"
        ],
        "correctAnswer": 0,
        "explanation": "Constraint checking removes invalid digits early to improve efficiency."
    },
    {
        "id": 173,
        "topic": "Paradigms",
        "algorithm": "Backtracking : Sudoku",
        "difficulty": "Hard",
        "question": "What is the worst-case complexity of solving Sudoku with naive backtracking?",
        "options": [
        "O(1)",
        "O(9^n)",
        "O(n^2)",
        "O(log n)"
        ],
        "correctAnswer": 1,
        "explanation": "Naive Sudoku solving can explore up to O(9^n) possibilities."
    },
    {
        "id": 174,
        "topic": "Paradigms",
        "algorithm": "Backtracking : Sudoku",
        "difficulty": "Hard",
        "question": "Which advanced human technique is difficult to implement programmatically?",
        "options": [
        "Naked pairs/triples",
        "Backtracking",
        "Binary Search",
        "Greedy heuristics"
        ],
        "correctAnswer": 0,
        "explanation": "Naked pairs/triples are advanced logical techniques used by humans in Sudoku solving."
    },
    {
        "id": 175,
        "topic": "Paradigms",
        "algorithm": "Backtracking : Rat in a Maze",
        "difficulty": "Easy",
        "question": "What is the main objective in the Rat in a Maze problem?",
        "options": [
        "Find all possible paths in a maze",
        "Count the number of walls",
        "Escape the maze in minimum steps",
        "Place the rat randomly"
        ],
        "correctAnswer": 0,
        "explanation": "The goal is to find all paths from start to finish using backtracking."
    },
    {
        "id": 176,
        "topic": "Paradigms",
        "algorithm": "Backtracking : Rat in a Maze",
        "difficulty": "Easy",
        "question": "Which of these structures represents the maze in this problem?",
        "options": [
        "Graph",
        "2D Matrix",
        "Linked List",
        "Stack"
        ],
        "correctAnswer": 1,
        "explanation": "A 2D matrix is commonly used to represent the maze with 0s and 1s."
    },
    {
        "id": 177,
        "topic": "Paradigms",
        "algorithm": "Backtracking : Rat in a Maze",
        "difficulty": "Medium",
        "question": "Which algorithmic approach is used to explore paths in the maze?",
        "options": [
        "Greedy",
        "Backtracking",
        "Dynamic Programming",
        "Divide and Conquer"
        ],
        "correctAnswer": 1,
        "explanation": "Backtracking systematically explores all possible paths and backtracks on dead ends."
    },
    {
        "id": 178,
        "topic": "Paradigms",
        "algorithm": "Backtracking : Rat in a Maze",
        "difficulty": "Medium",
        "question": "What condition is checked before moving the rat to the next cell?",
        "options": [
        "If the cell is within bounds and not blocked",
        "If the cell has already been visited",
        "If the cell contains a reward",
        "Both 1 and 2"
        ],
        "correctAnswer": 3,
        "explanation": "The rat moves only to valid, unvisited cells within the maze boundaries."
    },
    {
        "id": 179,
        "topic": "Paradigms",
        "algorithm": "Backtracking : Rat in a Maze",
        "difficulty": "Hard",
        "question": "What is the time complexity of finding all paths in an NN maze?",
        "options": [
        "O(N^2)",
        "O(2^(N^2))",
        "O(N!)",
        "O(N^N)"
        ],
        "correctAnswer": 1,
        "explanation": "The algorithm may explore all possible combinations of cells, giving O(2^(N^2)) complexity."
    },
    {
        "id": 180,
        "topic": "Paradigms",
        "algorithm": "Backtracking : Rat in a Maze",
        "difficulty": "Hard",
        "question": "Which optimization can reduce the search space in Rat in a Maze?",
        "options": [
        "Pruning visited paths",
        "Random moves",
        "Greedy selection",
        "Sorting the cells"
        ],
        "correctAnswer": 0,
        "explanation": "Pruning prevents revisiting paths, reducing unnecessary computation."
    },

    {
        "id": 181,
        "topic": "Paradigms",
        "algorithm": "Backtracking : Combination Sum",
        "difficulty": "Easy",
        "question": "What is the goal of the Combination Sum problem?",
        "options": [
        "Find a single combination of numbers",
        "Find all unique combinations that sum to target",
        "Sort numbers in ascending order",
        "Multiply numbers to reach target"
        ],
        "correctAnswer": 1,
        "explanation": "Combination Sum finds all combinations of numbers that add up to the target."
    },
    {
        "id": 182,
        "topic": "Paradigms",
        "algorithm": "Backtracking : Combination Sum",
        "difficulty": "Easy",
        "question": "Which of these constraints is usually applied?",
        "options": [
        "Numbers can be used only once",
        "Numbers can be repeated",
        "Numbers must be negative",
        "Only prime numbers are allowed"
        ],
        "correctAnswer": 1,
        "explanation": "Numbers can typically be used multiple times to form combinations."
    },
    {
        "id": 183,
        "topic": "Paradigms",
        "algorithm": "Backtracking : Combination Sum",
        "difficulty": "Medium",
        "question": "Which paradigm is commonly used to solve Combination Sum?",
        "options": [
        "Backtracking",
        "Greedy",
        "Dynamic Programming",
        "Divide and Conquer"
        ],
        "correctAnswer": 0,
        "explanation": "Backtracking explores all possible combinations and backtracks when necessary."
    },
    {
        "id": 184,
        "topic": "Paradigms",
        "algorithm": "Backtracking : Combination Sum",
        "difficulty": "Medium",
        "question": "How do we avoid duplicate combinations?",
        "options": [
        "Sort the input and explore in order",
        "Use a hash set for duplicates",
        "Both 1 and 2",
        "Ignore duplicates"
        ],
        "correctAnswer": 2,
        "explanation": "Sorting and using a set ensures unique combinations only."
    },
    {
        "id": 185,
        "topic": "Paradigms",
        "algorithm": "Backtracking : Combination Sum",
        "difficulty": "Hard",
        "question": "What is the worst-case complexity of Combination Sum backtracking solution?",
        "options": [
        "O(2^n)",
        "O(n^2)",
        "O(n!)",
        "O(n^n)"
        ],
        "correctAnswer": 0,
        "explanation": "The solution explores subsets of input, giving exponential time complexity O(2^n)."
    },
    {
        "id": 186,
        "topic": "Paradigms",
        "algorithm": "Backtracking : Combination Sum",
        "difficulty": "Hard",
        "question": "Which technique can optimize repeated sum calculations?",
        "options": [
        "Memoization",
        "Greedy selection",
        "Random sampling",
        "Sorting"
        ],
        "correctAnswer": 0,
        "explanation": "Memoization stores previously computed sums to avoid redundant work."
    },

    {
        "id": 187,
        "topic": "Paradigms",
        "algorithm": "Backtracking : Word Search",
        "difficulty": "Easy",
        "question": "What is the main goal of the Word Search problem?",
        "options": [
        "Find words in a grid of letters",
        "Count letters in a word",
        "Sort words alphabetically",
        "Replace letters randomly"
        ],
        "correctAnswer": 0,
        "explanation": "Word Search requires locating given words within a letter grid."
    },
    {
        "id": 188,
        "topic": "Paradigms",
        "algorithm": "Backtracking : Word Search",
        "difficulty": "Easy",
        "question": "Which directions are typically considered when searching?",
        "options": [
        "Horizontally and vertically",
        "Diagonally",
        "All 8 directions",
        "Only horizontally"
        ],
        "correctAnswer": 2,
        "explanation": "All 8 directions (horizontal, vertical, diagonal) are used to locate words."
    },
    {
        "id": 189,
        "topic": "Paradigms",
        "algorithm": "Backtracking : Word Search",
        "difficulty": "Medium",
        "question": "Which algorithmic technique is used for Word Search?",
        "options": [
        "Backtracking",
        "Dynamic Programming",
        "Greedy",
        "Divide and Conquer"
        ],
        "correctAnswer": 0,
        "explanation": "Backtracking is used to explore paths in the grid recursively."
    },
    {
        "id": 190,
        "topic": "Paradigms",
        "algorithm": "Backtracking : Word Search",
        "difficulty": "Medium",
        "question": "How can we prevent revisiting the same cell in a word path?",
        "options": [
        "Mark cells as visited during recursion",
        "Use a global counter",
        "Ignore visited cells",
        "Sort the grid"
        ],
        "correctAnswer": 0,
        "explanation": "Marking visited cells prevents cycles and incorrect paths."
    },
    {
        "id": 191,
        "topic": "Paradigms",
        "algorithm": "Backtracking : Word Search",
        "difficulty": "Hard",
        "question": "What is the worst-case time complexity for finding a word of length L in an NN grid?",
        "options": [
        "O(L)",
        "O(N^2 * 4^L)",
        "O(N^L)",
        "O(N!)"
        ],
        "correctAnswer": 1,
        "explanation": "Each letter has up to 4 directions, giving O(N^2 * 4^L) in the worst case."
    },
    {
        "id": 192,
        "topic": "Paradigms",
        "algorithm": "Backtracking : Word Search",
        "difficulty": "Hard",
        "question": "Which optimization can reduce the search in Word Search?",
        "options": [
        "Trie for prefix checking",
        "Random cell selection",
        "Sorting words",
        "Greedy search"
        ],
        "correctAnswer": 0,
        "explanation": "Using a Trie allows early pruning if no word starts with the current prefix."
    },
    {
        "id": 193,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Fibonacci Sequence",
        "difficulty": "Easy",
        "question": "What is the 0th Fibonacci number?",
        "options": [
        "0",
        "1",
        "2",
        "Undefined"
        ],
        "correctAnswer": 0,
        "explanation": "The Fibonacci sequence starts with 0 as the 0th element."
    },
    {
        "id": 194,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Fibonacci Sequence",
        "difficulty": "Easy",
        "question": "Which recurrence relation defines Fibonacci numbers?",
        "options": [
        "F(n) = F(n-1) + F(n-2)",
        "F(n) = F(n-1) * F(n-2)",
        "F(n) = F(n-2) - F(n-1)",
        "F(n) = n^2"
        ],
        "correctAnswer": 0,
        "explanation": "Each Fibonacci number is the sum of the two preceding numbers."
    },
    {
        "id": 195,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Fibonacci Sequence",
        "difficulty": "Medium",
        "question": "Which approach avoids exponential recursion in Fibonacci calculation?",
        "options": [
        "Backtracking",
        "Memoization",
        "Greedy",
        "Sorting"
        ],
        "correctAnswer": 1,
        "explanation": "Memoization stores previously computed results to prevent repeated calculations."
    },
    {
        "id": 196,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Fibonacci Sequence",
        "difficulty": "Medium",
        "question": "What is the time complexity of Fibonacci with memoization?",
        "options": [
        "O(2^n)",
        "O(n)",
        "O(n^2)",
        "O(log n)"
        ],
        "correctAnswer": 1,
        "explanation": "Memoization reduces the time complexity to linear O(n)."
    },
    {
        "id": 197,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Fibonacci Sequence",
        "difficulty": "Hard",
        "question": "Which space optimization can be applied to Fibonacci DP?",
        "options": [
        "Using two variables instead of an array",
        "Using a stack",
        "Using recursion only",
        "Using sorting"
        ],
        "correctAnswer": 0,
        "explanation": "Only the last two numbers are needed, so we can use two variables to reduce space."
    },
    {
        "id": 198,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Fibonacci Sequence",
        "difficulty": "Hard",
        "question": "Which formula allows O(log n) Fibonacci computation?",
        "options": [
        "Binet's formula / Matrix exponentiation",
        "Greedy summation",
        "Backtracking",
        "Linear DP"
        ],
        "correctAnswer": 0,
        "explanation": "Matrix exponentiation or Binet's formula computes Fibonacci in logarithmic time."
    },

    {
        "id": 199,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : 0/1 Knapsack",
        "difficulty": "Easy",
        "question": "In 0/1 Knapsack, each item can be:",
        "options": [
        "Taken multiple times",
        "Taken once or not taken",
        "Taken partially",
        "Ignored completely"
        ],
        "correctAnswer": 1,
        "explanation": "Each item can either be included once or excluded."
    },
    {
        "id": 200,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : 0/1 Knapsack",
        "difficulty": "Easy",
        "question": "What is the main goal of 0/1 Knapsack?",
        "options": [
        "Maximize profit without exceeding weight",
        "Minimize weight",
        "Sort items by value",
        "Select items randomly"
        ],
        "correctAnswer": 0,
        "explanation": "We aim to maximize total value while staying within the weight limit."
    },
    {
        "id": 201,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : 0/1 Knapsack",
        "difficulty": "Medium",
        "question": "Which DP table size is commonly used for 0/1 Knapsack?",
        "options": [
        "n  W",
        "n  n",
        "W  W",
        "1D array only"
        ],
        "correctAnswer": 0,
        "explanation": "The DP table has dimensions [number of items]  [capacity W]."
    },
    {
        "id": 202,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : 0/1 Knapsack",
        "difficulty": "Medium",
        "question": "What recurrence relation is used in 0/1 Knapsack?",
        "options": [
        "dp[i][w] = max(dp[i-1][w], dp[i-1][w-weight[i]] + value[i])",
        "dp[i][w] = dp[i-1][w] + dp[i-1][w-weight[i]]",
        "dp[i][w] = min(dp[i-1][w], dp[i-1][w-weight[i]] + value[i])",
        "dp[i][w] = dp[i-1][w] * value[i]"
        ],
        "correctAnswer": 0,
        "explanation": "The DP formula considers including or excluding the current item."
    },
    {
        "id": 203,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : 0/1 Knapsack",
        "difficulty": "Hard",
        "question": "What is the time complexity of standard DP 0/1 Knapsack?",
        "options": [
        "O(n*W)",
        "O(n^2)",
        "O(2^n)",
        "O(n*log W)"
        ],
        "correctAnswer": 0,
        "explanation": "Time complexity is O(n*W) where n = number of items and W = capacity."
    },
    {
        "id": 204,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : 0/1 Knapsack",
        "difficulty": "Hard",
        "question": "Which optimization reduces space to O(W) in 0/1 Knapsack?",
        "options": [
        "Using a 1D DP array and iterating weights in reverse",
        "Using recursion only",
        "Sorting items first",
        "Greedy selection"
        ],
        "correctAnswer": 0,
        "explanation": "1D DP array with reverse iteration reduces space while maintaining correctness."
    },

    {
        "id": 205,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Coin Change",
        "difficulty": "Easy",
        "question": "What is the Coin Change problem?",
        "options": [
        "Find the minimum number of coins to make a target",
        "Count total coins available",
        "Sort coins",
        "Maximize coin value"
        ],
        "correctAnswer": 0,
        "explanation": "We aim to make a target amount using the fewest coins."
    },
    {
        "id": 206,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Coin Change",
        "difficulty": "Easy",
        "question": "Which type of DP is used in Coin Change problem?",
        "options": [
        "Top-down with memoization",
        "Greedy only",
        "Divide and Conquer",
        "Backtracking only"
        ],
        "correctAnswer": 0,
        "explanation": "Top-down (or bottom-up) DP is used to avoid recomputation."
    },
    {
        "id": 207,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Coin Change",
        "difficulty": "Medium",
        "question": "Which DP table represents the minimum coins for each amount?",
        "options": [
        "dp[amount]",
        "dp[coins]",
        "dp[value]",
        "dp[weight]"
        ],
        "correctAnswer": 0,
        "explanation": "dp[i] stores the minimum coins needed to make amount i."
    },
    {
        "id": 208,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Coin Change",
        "difficulty": "Medium",
        "question": "How to handle amounts that cannot be formed?",
        "options": [
        "Initialize with INF or large value",
        "Use 0",
        "Skip them",
        "Use negative numbers"
        ],
        "correctAnswer": 0,
        "explanation": "Initialize DP with a large number to indicate unreachable amounts."
    },
    {
        "id": 209,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Coin Change",
        "difficulty": "Hard",
        "question": "What is the time complexity of DP Coin Change with n coins and amount A?",
        "options": [
        "O(n*A)",
        "O(A^n)",
        "O(n^2)",
        "O(n*log A)"
        ],
        "correctAnswer": 0,
        "explanation": "Each amount is computed by iterating over n coins, giving O(n*A)."
    },
    {
        "id": 210,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Coin Change",
        "difficulty": "Hard",
        "question": "Which optimization can reduce space in Coin Change DP?",
        "options": [
        "1D array storing min coins for each amount",
        "Sorting coins",
        "Greedy selection",
        "Recursive stack only"
        ],
        "correctAnswer": 0,
        "explanation": "Only 1D array of size amount+1 is needed, reducing space."
    },
    {
        "id": 211,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Longest Common Subsequence",
        "difficulty": "Easy",
        "question": "What does LCS stand for?",
        "options": [
        "Longest Continuous Subarray",
        "Longest Common Subsequence",
        "Largest Common Sum",
        "Least Common Subsequence"
        ],
        "correctAnswer": 1,
        "explanation": "LCS stands for Longest Common Subsequence."
    },
    {
        "id": 212,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Longest Common Subsequence",
        "difficulty": "Easy",
        "question": "Which of these pairs has an LCS of length 3?",
        "options": [
        "ABCD & ACBD",
        "ABC & DEF",
        "XYZ & XYZ",
        "AA & BB"
        ],
        "correctAnswer": 0,
        "explanation": "ABCD and ACBD share 'ABD' as a common subsequence of length 3."
    },
    {
        "id": 213,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Longest Common Subsequence",
        "difficulty": "Medium",
        "question": "Which recurrence defines LCS?",
        "options": [
        "If X[i] = Y[j], dp[i][j] = dp[i-1][j-1]+1 else max(dp[i-1][j], dp[i][j-1])",
        "dp[i][j] = dp[i-1][j] + dp[i][j-1]",
        "dp[i][j] = dp[i-1][j-1]",
        "dp[i][j] = max(dp[i][j-1], dp[i-1][j-1])"
        ],
        "correctAnswer": 0,
        "explanation": "The standard LCS recurrence considers match or max of previous subproblems."
    },
    {
        "id": 214,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Longest Common Subsequence",
        "difficulty": "Medium",
        "question": "Which DP table size is used for sequences of length m and n?",
        "options": [
        "m  n",
        "m + n",
        "2  max(m,n)",
        "m^2"
        ],
        "correctAnswer": 0,
        "explanation": "The DP table has dimensions [m+1][n+1]."
    },
    {
        "id": 215,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Longest Common Subsequence",
        "difficulty": "Hard",
        "question": "What is the time complexity of LCS DP solution?",
        "options": [
        "O(m+n)",
        "O(m*n)",
        "O(2^n)",
        "O(n!)"
        ],
        "correctAnswer": 1,
        "explanation": "The standard DP solution computes each cell once, giving O(m*n)."
    },
    {
        "id": 216,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Longest Common Subsequence",
        "difficulty": "Hard",
        "question": "Which optimization reduces space to O(min(m,n))?",
        "options": [
        "Using only two rows of DP table",
        "Memoization with recursion",
        "Greedy LCS",
        "Sorting sequences"
        ],
        "correctAnswer": 0,
        "explanation": "Storing only previous and current row suffices for DP computation."
    },

    {
        "id": 217,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Matrix Chain Multiplication",
        "difficulty": "Easy",
        "question": "What is the goal in Matrix Chain Multiplication?",
        "options": [
        "Multiply matrices in any order",
        "Minimize total scalar multiplications",
        "Maximize determinant",
        "Sort matrices by size"
        ],
        "correctAnswer": 1,
        "explanation": "We seek the order that minimizes scalar multiplications."
    },
    {
        "id": 218,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Matrix Chain Multiplication",
        "difficulty": "Easy",
        "question": "Which operation counts in cost calculation?",
        "options": [
        "Matrix addition",
        "Scalar multiplications",
        "Matrix inversion",
        "Determinant"
        ],
        "correctAnswer": 1,
        "explanation": "The number of scalar multiplications determines the cost."
    },
    {
        "id": 219,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Matrix Chain Multiplication",
        "difficulty": "Medium",
        "question": "Which DP approach is used?",
        "options": [
        "Bottom-up",
        "Greedy",
        "Divide and Conquer without DP",
        "Backtracking"
        ],
        "correctAnswer": 0,
        "explanation": "Bottom-up DP computes minimum costs for increasing chain lengths."
    },
    {
        "id": 220,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Matrix Chain Multiplication",
        "difficulty": "Medium",
        "question": "What does dp[i][j] represent?",
        "options": [
        "Minimum cost to multiply matrices i to j",
        "Maximum cost",
        "Sum of matrix elements",
        "Matrix dimensions"
        ],
        "correctAnswer": 0,
        "explanation": "dp[i][j] stores the minimal scalar multiplication cost for matrices i..j."
    },
    {
        "id": 221,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Matrix Chain Multiplication",
        "difficulty": "Hard",
        "question": "Time complexity of standard DP solution?",
        "options": [
        "O(n^2)",
        "O(n^3)",
        "O(2^n)",
        "O(n!)"
        ],
        "correctAnswer": 1,
        "explanation": "Triple nested loops yield O(n^3) complexity."
    },
    {
        "id": 222,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Matrix Chain Multiplication",
        "difficulty": "Hard",
        "question": "Which optimization can reconstruct optimal multiplication order?",
        "options": [
        "Store split points in separate table",
        "Memoize recursively",
        "Sort matrices",
        "Greedy splitting"
        ],
        "correctAnswer": 0,
        "explanation": "A table of split indices allows reconstruction of the optimal order."
    },

    {
        "id": 223,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Minimum Path Sum",
        "difficulty": "Easy",
        "question": "What is the problem statement?",
        "options": [
        "Find path with minimum sum from top-left to bottom-right",
        "Maximize path sum",
        "Count number of paths",
        "Sort grid values"
        ],
        "correctAnswer": 0,
        "explanation": "The goal is to find a path with the smallest sum."
    },
    {
        "id": 224,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Minimum Path Sum",
        "difficulty": "Easy",
        "question": "Which moves are allowed?",
        "options": [
        "Down or Right",
        "Up or Left",
        "Diagonally only",
        "All 8 directions"
        ],
        "correctAnswer": 0,
        "explanation": "Only right and down moves are allowed in standard formulation."
    },
    {
        "id": 225,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Minimum Path Sum",
        "difficulty": "Medium",
        "question": "Which recurrence is used?",
        "options": [
        "dp[i][j] = grid[i][j] + min(dp[i-1][j], dp[i][j-1])",
        "dp[i][j] = grid[i][j] + max(dp[i-1][j], dp[i][j-1])",
        "dp[i][j] = grid[i][j] * dp[i-1][j]",
        "dp[i][j] = dp[i-1][j-1]"
        ],
        "correctAnswer": 0,
        "explanation": "The minimum path sum is current cell plus min of top or left."
    },
    {
        "id": 226,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Minimum Path Sum",
        "difficulty": "Medium",
        "question": "Time complexity for an mn grid?",
        "options": [
        "O(m*n)",
        "O(m+n)",
        "O(2^(m*n))",
        "O(m^2*n^2)"
        ],
        "correctAnswer": 0,
        "explanation": "Each cell is computed once, giving O(m*n)."
    },
    {
        "id": 227,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Minimum Path Sum",
        "difficulty": "Hard",
        "question": "Which space optimization is possible?",
        "options": [
        "Use a single row or column",
        "Use recursion only",
        "Store full DP table",
        "Sort the grid"
        ],
        "correctAnswer": 0,
        "explanation": "Only previous row or column is needed for DP computation."
    },
    {
        "id": 228,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Minimum Path Sum",
        "difficulty": "Hard",
        "question": "Which variant allows diagonal moves?",
        "options": [
        "Diagonal DP variant",
        "0/1 Knapsack",
        "Fibonacci",
        "LCS"
        ],
        "correctAnswer": 0,
        "explanation": "Allowing diagonal moves requires updating the DP formula to consider diagonal predecessor."
    },

    {
        "id": 229,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Subset Sum",
        "difficulty": "Easy",
        "question": "What is the problem statement?",
        "options": [
        "Check if a subset sums to target",
        "Find all subsets",
        "Sort numbers",
        "Find max element"
        ],
        "correctAnswer": 0,
        "explanation": "Subset Sum checks if any subset sums to a given target."
    },
    {
        "id": 230,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Subset Sum",
        "difficulty": "Easy",
        "question": "Which of these is a valid DP approach?",
        "options": [
        "dp[i][j] = dp[i-1][j] || dp[i-1][j-arr[i]]",
        "dp[i][j] = dp[i-1][j] + arr[i]",
        "dp[i][j] = dp[i][j-1]",
        "dp[i][j] = arr[i]*arr[j]"
        ],
        "correctAnswer": 0,
        "explanation": "DP tracks whether a sum j can be formed using first i elements."
    },
    {
        "id": 231,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Subset Sum",
        "difficulty": "Medium",
        "question": "Time complexity of standard DP Subset Sum?",
        "options": [
        "O(n*target)",
        "O(n^2)",
        "O(2^n)",
        "O(n!)"
        ],
        "correctAnswer": 0,
        "explanation": "We iterate over n elements and sums up to target."
    },
    {
        "id": 232,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Subset Sum",
        "difficulty": "Medium",
        "question": "Space optimization possible?",
        "options": [
        "Use 1D array of size target+1",
        "Use recursion only",
        "Sort elements",
        "Use 2D array always"
        ],
        "correctAnswer": 0,
        "explanation": "1D array suffices by updating from target downwards."
    },
    {
        "id": 233,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Subset Sum",
        "difficulty": "Hard",
        "question": "Subset Sum problem is a special case of which problem?",
        "options": [
        "0/1 Knapsack",
        "Coin Change",
        "Fibonacci",
        "LCS"
        ],
        "correctAnswer": 0,
        "explanation": "Subset Sum is a 0/1 Knapsack variant where item values = weights and capacity = target."
    },
    {
        "id": 234,
        "topic": "Paradigms",
        "algorithm": "Dynamic Programming : Subset Sum",
        "difficulty": "Hard",
        "question": "Which technique can solve large Subset Sum instances efficiently?",
        "options": [
        "Bitset DP or optimized space DP",
        "Greedy",
        "Sorting",
        "Backtracking only"
        ],
        "correctAnswer": 0,
        "explanation": "Bitset DP or optimized 1D DP allows handling large sums efficiently."
    },
    {
        "id": 235,
        "topic": "Paradigms",
        "algorithm": "Greedy Algorithms : Activity Selection",
        "difficulty": "Easy",
        "question": "What is the main goal of the Activity Selection problem?",
        "options": [
        "Maximize number of non-overlapping activities",
        "Minimize activity duration",
        "Sort activities by name",
        "Maximize total duration"
        ],
        "correctAnswer": 0,
        "explanation": "The goal is to select the maximum number of activities that don't overlap."
    },
    {
        "id": 236,
        "topic": "Paradigms",
        "algorithm": "Greedy Algorithms : Activity Selection",
        "difficulty": "Easy",
        "question": "Which greedy criterion is used?",
        "options": [
        "Earliest finish time first",
        "Longest duration first",
        "Random selection",
        "Latest start time first"
        ],
        "correctAnswer": 0,
        "explanation": "Choosing activities by earliest finish time ensures optimal selection."
    },
    {
        "id": 237,
        "topic": "Paradigms",
        "algorithm": "Greedy Algorithms : Activity Selection",
        "difficulty": "Medium",
        "question": "Time complexity of standard greedy solution after sorting?",
        "options": [
        "O(n log n)",
        "O(n^2)",
        "O(n)",
        "O(log n)"
        ],
        "correctAnswer": 0,
        "explanation": "Sorting takes O(n log n), selection afterward is O(n)."
    },
    {
        "id": 238,
        "topic": "Paradigms",
        "algorithm": "Greedy Algorithms : Activity Selection",
        "difficulty": "Medium",
        "question": "What data structure is commonly used for activity representation?",
        "options": [
        "Array or list of (start, end) times",
        "Graph adjacency matrix",
        "Stack",
        "Queue"
        ],
        "correctAnswer": 0,
        "explanation": "Each activity is represented by its start and finish time."
    },
    {
        "id": 239,
        "topic": "Paradigms",
        "algorithm": "Greedy Algorithms : Activity Selection",
        "difficulty": "Hard",
        "question": "Which is true about greedy correctness?",
        "options": [
        "Earliest finish time greedy gives optimal solution",
        "Random selection gives optimal solution",
        "Longest duration gives optimal solution",
        "None of the above"
        ],
        "correctAnswer": 0,
        "explanation": "Earliest finish time is proven to produce the maximum number of activities."
    },
    {
        "id": 240,
        "topic": "Paradigms",
        "algorithm": "Greedy Algorithms : Activity Selection",
        "difficulty": "Hard",
        "question": "Which proof technique shows correctness?",
        "options": [
        "Greedy stays ahead / exchange argument",
        "Dynamic programming",
        "Recursion",
        "Divide and Conquer"
        ],
        "correctAnswer": 0,
        "explanation": "Exchange argument demonstrates greedy choice leads to optimal solution."
    },

    {
        "id": 241,
        "topic": "Paradigms",
        "algorithm": "Greedy Algorithms : Fractional Knapsack",
        "difficulty": "Easy",
        "question": "What is allowed in Fractional Knapsack?",
        "options": [
        "Take fractions of items",
        "Take each item only once",
        "Skip items completely",
        "Sort items by name"
        ],
        "correctAnswer": 0,
        "explanation": "Unlike 0/1 Knapsack, items can be taken partially."
    },
    {
        "id": 242,
        "topic": "Paradigms",
        "algorithm": "Greedy Algorithms : Fractional Knapsack",
        "difficulty": "Easy",
        "question": "Which criterion is used to select items?",
        "options": [
        "Highest value/weight ratio first",
        "Lowest value first",
        "Random order",
        "Longest item first"
        ],
        "correctAnswer": 0,
        "explanation": "Greedy choice selects items with highest value-to-weight ratio."
    },
    {
        "id": 243,
        "topic": "Paradigms",
        "algorithm": "Greedy Algorithms : Fractional Knapsack",
        "difficulty": "Medium",
        "question": "Time complexity after sorting n items?",
        "options": [
        "O(n log n)",
        "O(n^2)",
        "O(n)",
        "O(log n)"
        ],
        "correctAnswer": 0,
        "explanation": "Sorting dominates the algorithm; selection is linear."
    },
    {
        "id": 244,
        "topic": "Paradigms",
        "algorithm": "Greedy Algorithms : Fractional Knapsack",
        "difficulty": "Medium",
        "question": "Which data structure is commonly used to sort items?",
        "options": [
        "Array or list",
        "Queue",
        "Graph",
        "Stack"
        ],
        "correctAnswer": 0,
        "explanation": "Items are sorted in an array/list by value/weight ratio."
    },
    {
        "id": 245,
        "topic": "Paradigms",
        "algorithm": "Greedy Algorithms : Fractional Knapsack",
        "difficulty": "Hard",
        "question": "Why is greedy optimal for Fractional Knapsack?",
        "options": [
        "Fractional property allows linear combination of best ratios",
        "Because recursion works",
        "Sorting guarantees minimal weight",
        "Random choice works"
        ],
        "correctAnswer": 0,
        "explanation": "Fractions allow us to always take as much as possible from the best ratio item."
    },
    {
        "id": 246,
        "topic": "Paradigms",
        "algorithm": "Greedy Algorithms : Fractional Knapsack",
        "difficulty": "Hard",
        "question": "Time complexity if items are unsorted?",
        "options": [
        "O(n log n)",
        "O(n^2)",
        "O(n)",
        "O(log n)"
        ],
        "correctAnswer": 0,
        "explanation": "Sorting is necessary before linear selection; otherwise, cannot guarantee optimality."
    },

    {
        "id": 247,
        "topic": "Paradigms",
        "algorithm": "Greedy Algorithms : Huffman Encoding",
        "difficulty": "Easy",
        "question": "What is Huffman Encoding used for?",
        "options": [
        "Data compression",
        "Sorting numbers",
        "Finding shortest paths",
        "Graph traversal"
        ],
        "correctAnswer": 0,
        "explanation": "Huffman encoding compresses data by using variable-length codes."
    },
    {
        "id": 248,
        "topic": "Paradigms",
        "algorithm": "Greedy Algorithms : Huffman Encoding",
        "difficulty": "Easy",
        "question": "Which data structure is used?",
        "options": [
        "Min-heap or priority queue",
        "Stack",
        "Queue",
        "Array only"
        ],
        "correctAnswer": 0,
        "explanation": "A min-heap efficiently extracts the two lowest frequency nodes repeatedly."
    },
    {
        "id": 249,
        "topic": "Paradigms",
        "algorithm": "Greedy Algorithms : Huffman Encoding",
        "difficulty": "Medium",
        "question": "Greedy choice in Huffman?",
        "options": [
        "Combine two nodes with smallest frequencies",
        "Choose largest node",
        "Random nodes",
        "Sort characters alphabetically"
        ],
        "correctAnswer": 0,
        "explanation": "Always combine two smallest frequencies to form a new node."
    },
    {
        "id": 250,
        "topic": "Paradigms",
        "algorithm": "Greedy Algorithms : Huffman Encoding",
        "difficulty": "Medium",
        "question": "Time complexity for n characters?",
        "options": [
        "O(n log n)",
        "O(n^2)",
        "O(n)",
        "O(log n)"
        ],
        "correctAnswer": 0,
        "explanation": "Building min-heap takes O(n log n) and each merge is logarithmic."
    },
    {
        "id": 251,
        "topic": "Paradigms",
        "algorithm": "Greedy Algorithms : Huffman Encoding",
        "difficulty": "Hard",
        "question": "Why is greedy optimal for Huffman?",
        "options": [
        "Optimal prefix property ensures minimal encoding length",
        "Because recursion works",
        "Sorting guarantees minimal weight",
        "Random choice works"
        ],
        "correctAnswer": 0,
        "explanation": "Greedy choice ensures the resulting prefix code has minimal total weighted path length."
    },
    {
        "id": 252,
        "topic": "Paradigms",
        "algorithm": "Greedy Algorithms : Huffman Encoding",
        "difficulty": "Hard",
        "question": "Which proof method shows optimality?",
        "options": [
        "Greedy stays ahead / exchange argument",
        "Dynamic programming",
        "Recursion only",
        "Divide and Conquer"
        ],
        "correctAnswer": 0,
        "explanation": "Exchange argument proves combining smallest frequencies is optimal."
    },
    {
        "id": 253,
        "topic": "Paradigms",
        "algorithm": "Greedy Algorithms : Job Scheduling",
        "difficulty": "Easy",
        "question": "What is the goal in the Job Scheduling problem?",
        "options": [
        "Maximize profit by scheduling non-overlapping jobs",
        "Minimize job durations",
        "Sort jobs by name",
        "Maximize number of jobs"
        ],
        "correctAnswer": 0,
        "explanation": "The goal is to select jobs to maximize total profit without conflicts."
    },
    {
        "id": 254,
        "topic": "Paradigms",
        "algorithm": "Greedy Algorithms : Job Scheduling",
        "difficulty": "Easy",
        "question": "Which criterion is commonly used to schedule jobs?",
        "options": [
        "Earliest deadline first",
        "Longest processing time first",
        "Random selection",
        "Alphabetical order"
        ],
        "correctAnswer": 0,
        "explanation": "Earliest deadline first ensures feasible scheduling and often optimal profit."
    },
    {
        "id": 255,
        "topic": "Paradigms",
        "algorithm": "Greedy Algorithms : Job Scheduling",
        "difficulty": "Medium",
        "question": "Time complexity after sorting n jobs by deadline?",
        "options": [
        "O(n log n)",
        "O(n^2)",
        "O(n)",
        "O(log n)"
        ],
        "correctAnswer": 0,
        "explanation": "Sorting dominates; selection afterward is linear."
    },
    {
        "id": 256,
        "topic": "Paradigms",
        "algorithm": "Greedy Algorithms : Job Scheduling",
        "difficulty": "Medium",
        "question": "Which data structure can help track free time slots efficiently?",
        "options": [
        "Disjoint set / Union-Find",
        "Stack",
        "Queue",
        "Array only"
        ],
        "correctAnswer": 0,
        "explanation": "Union-Find helps efficiently find the latest available slot."
    },
    {
        "id": 257,
        "topic": "Paradigms",
        "algorithm": "Greedy Algorithms : Job Scheduling",
        "difficulty": "Hard",
        "question": "Greedy optimality proof often uses which technique?",
        "options": [
        "Exchange argument",
        "Dynamic programming",
        "Recursion only",
        "Divide and Conquer"
        ],
        "correctAnswer": 0,
        "explanation": "Exchange argument shows that swapping jobs maintains optimal profit."
    },
    {
        "id": 258,
        "topic": "Paradigms",
        "algorithm": "Greedy Algorithms : Job Scheduling",
        "difficulty": "Hard",
        "question": "Which variant allows fractional scheduling?",
        "options": [
        "Job Fractional Scheduling (like Fractional Knapsack)",
        "0/1 Job Scheduling",
        "Random scheduling",
        "None"
        ],
        "correctAnswer": 0,
        "explanation": "Fractional scheduling allows splitting jobs partially to maximize profit."
    },

    {
        "id": 259,
        "topic": "Paradigms",
        "algorithm": "Greedy Algorithms : Minimum Spanning Tree",
        "difficulty": "Easy",
        "question": "What is the goal of MST?",
        "options": [
        "Connect all vertices with minimum total edge weight",
        "Maximize total edge weight",
        "Count number of edges",
        "Sort vertices"
        ],
        "correctAnswer": 0,
        "explanation": "MST connects all vertices using the minimum total edge weight."
    },
    {
        "id": 260,
        "topic": "Paradigms",
        "algorithm": "Greedy Algorithms : Minimum Spanning Tree",
        "difficulty": "Easy",
        "question": "Which algorithms are greedy for MST?",
        "options": [
        "Prim and Kruskal",
        "Dijkstra and BFS",
        "DFS and Bellman-Ford",
        "Floyd-Warshall"
        ],
        "correctAnswer": 0,
        "explanation": "Prim and Kruskal build MSTs greedily by choosing minimum edges."
    },
    {
        "id": 261,
        "topic": "Paradigms",
        "algorithm": "Greedy Algorithms : Minimum Spanning Tree",
        "difficulty": "Medium",
        "question": "Kruskals algorithm requires which data structure?",
        "options": [
        "Disjoint set / Union-Find",
        "Queue",
        "Stack",
        "Heap only"
        ],
        "correctAnswer": 0,
        "explanation": "Union-Find detects cycles efficiently when adding edges."
    },
    {
        "id": 262,
        "topic": "Paradigms",
        "algorithm": "Greedy Algorithms : Minimum Spanning Tree",
        "difficulty": "Medium",
        "question": "Prims algorithm can be implemented efficiently using which structure?",
        "options": [
        "Min-heap / Priority queue",
        "Stack",
        "Disjoint set",
        "Array only"
        ],
        "correctAnswer": 0,
        "explanation": "Priority queue efficiently picks the next minimum edge connecting the MST."
    },
    {
        "id": 263,
        "topic": "Paradigms",
        "algorithm": "Greedy Algorithms : Minimum Spanning Tree",
        "difficulty": "Hard",
        "question": "Time complexity of Kruskals algorithm with n vertices and m edges?",
        "options": [
        "O(m log m + m (n))",
        "O(n^2)",
        "O(n log n)",
        "O(m^2)"
        ],
        "correctAnswer": 0,
        "explanation": "Sorting edges is O(m log m) and Union-Find operations are near constant ((n))."
    },
    {
        "id": 264,
        "topic": "Paradigms",
        "algorithm": "Greedy Algorithms : Minimum Spanning Tree",
        "difficulty": "Hard",
        "question": "Time complexity of Prims algorithm using min-heap?",
        "options": [
        "O((V+E) log V)",
        "O(V^2)",
        "O(E^2)",
        "O(V log V)"
        ],
        "correctAnswer": 0,
        "explanation": "Each edge may trigger a heap update, giving O((V+E) log V) complexity."
    },
    {
        "id": 265,
        "topic": "Paradigms",
        "algorithm": "Divide & Conquer : Merge Sort",
        "difficulty": "Easy",
        "question": "Which paradigm does Merge Sort use?",
        "options": [
        "Divide and Conquer",
        "Greedy",
        "Dynamic Programming",
        "Backtracking"
        ],
        "correctAnswer": 0,
        "explanation": "Merge Sort divides the array, sorts recursively, and merges  classic divide and conquer."
    },
    {
        "id": 266,
        "topic": "Paradigms",
        "algorithm": "Divide & Conquer : Merge Sort",
        "difficulty": "Easy",
        "question": "What is the time complexity of Merge Sort in the worst case?",
        "options": [
        "O(n log n)",
        "O(n^2)",
        "O(log n)",
        "O(n)"
        ],
        "correctAnswer": 0,
        "explanation": "Merge Sort always divides and merges, giving O(n log n) complexity."
    },
    {
        "id": 267,
        "topic": "Paradigms",
        "algorithm": "Divide & Conquer : Merge Sort",
        "difficulty": "Medium",
        "question": "Which data structure is commonly used during merging?",
        "options": [
        "Temporary array",
        "Stack",
        "Queue",
        "Linked list only"
        ],
        "correctAnswer": 0,
        "explanation": "A temporary array stores merged elements before copying back."
    },
    {
        "id": 268,
        "topic": "Paradigms",
        "algorithm": "Divide & Conquer : Merge Sort",
        "difficulty": "Medium",
        "question": "Space complexity of Merge Sort?",
        "options": [
        "O(n)",
        "O(1)",
        "O(log n)",
        "O(n^2)"
        ],
        "correctAnswer": 0,
        "explanation": "Merge Sort requires O(n) extra space for the temporary array."
    },
    {
        "id": 269,
        "topic": "Paradigms",
        "algorithm": "Divide & Conquer : Merge Sort",
        "difficulty": "Hard",
        "question": "Which technique can reduce Merge Sorts space usage?",
        "options": [
        "In-place merging",
        "Greedy selection",
        "Recursion only",
        "Backtracking"
        ],
        "correctAnswer": 0,
        "explanation": "In-place merging techniques reduce additional memory, though more complex."
    },
    {
        "id": 270,
        "topic": "Paradigms",
        "algorithm": "Divide & Conquer : Merge Sort",
        "difficulty": "Hard",
        "question": "Merge Sort is stable. What does stability mean?",
        "options": [
        "Equal elements retain relative order",
        "Always fastest sorting",
        "Requires extra memory",
        "Divides array recursively"
        ],
        "correctAnswer": 0,
        "explanation": "Stability preserves the order of equal elements after sorting."
    },

    {
        "id": 271,
        "topic": "Paradigms",
        "algorithm": "Divide & Conquer : Quick Sort",
        "difficulty": "Easy",
        "question": "Which paradigm does Quick Sort use?",
        "options": [
        "Divide and Conquer",
        "Greedy",
        "Dynamic Programming",
        "Backtracking"
        ],
        "correctAnswer": 0,
        "explanation": "Quick Sort divides the array around a pivot and conquers recursively."
    },
    {
        "id": 272,
        "topic": "Paradigms",
        "algorithm": "Divide & Conquer : Quick Sort",
        "difficulty": "Easy",
        "question": "Worst-case time complexity of Quick Sort?",
        "options": [
        "O(n^2)",
        "O(n log n)",
        "O(log n)",
        "O(n)"
        ],
        "correctAnswer": 0,
        "explanation": "If pivot selection is poor (sorted array), Quick Sort degrades to O(n^2)."
    },
    {
        "id": 273,
        "topic": "Paradigms",
        "algorithm": "Divide & Conquer : Quick Sort",
        "difficulty": "Medium",
        "question": "Which pivot selection technique is commonly used?",
        "options": [
        "Randomized or median-of-three",
        "First element always",
        "Last element only",
        "Middle element only"
        ],
        "correctAnswer": 0,
        "explanation": "Random or median-of-three pivot improves average performance and reduces worst-case likelihood."
    },
    {
        "id": 274,
        "topic": "Paradigms",
        "algorithm": "Divide & Conquer : Quick Sort",
        "difficulty": "Medium",
        "question": "Average-case time complexity?",
        "options": [
        "O(n log n)",
        "O(n^2)",
        "O(log n)",
        "O(n)"
        ],
        "correctAnswer": 0,
        "explanation": "With balanced partitioning, Quick Sort runs in O(n log n) on average."
    },
    {
        "id": 275,
        "topic": "Paradigms",
        "algorithm": "Divide & Conquer : Quick Sort",
        "difficulty": "Hard",
        "question": "Is Quick Sort stable?",
        "options": [
        "No",
        "Yes",
        "Only for small arrays",
        "Depends on pivot"
        ],
        "correctAnswer": 0,
        "explanation": "Standard Quick Sort is not stable; equal elements may change relative order."
    },
    {
        "id": 276,
        "topic": "Paradigms",
        "algorithm": "Divide & Conquer : Quick Sort",
        "difficulty": "Hard",
        "question": "Space complexity of Quick Sort (recursive)?",
        "options": [
        "O(log n) average",
        "O(n)",
        "O(n log n)",
        "O(1)"
        ],
        "correctAnswer": 0,
        "explanation": "Recursive calls use O(log n) stack space on average."
    },

    {
        "id": 277,
        "topic": "Paradigms",
        "algorithm": "Divide & Conquer : Binary Search",
        "difficulty": "Easy",
        "question": "Binary Search works on which type of array?",
        "options": [
        "Sorted array",
        "Unsorted array",
        "Random array",
        "Linked list only"
        ],
        "correctAnswer": 0,
        "explanation": "Binary Search requires a sorted array to divide search space efficiently."
    },
    {
        "id": 278,
        "topic": "Paradigms",
        "algorithm": "Divide & Conquer : Binary Search",
        "difficulty": "Easy",
        "question": "Time complexity of Binary Search?",
        "options": [
        "O(log n)",
        "O(n)",
        "O(n log n)",
        "O(n^2)"
        ],
        "correctAnswer": 0,
        "explanation": "Each step halves the search space, giving O(log n)."
    },
    {
        "id": 279,
        "topic": "Paradigms",
        "algorithm": "Divide & Conquer : Binary Search",
        "difficulty": "Medium",
        "question": "Which implementation is more space-efficient?",
        "options": [
        "Iterative",
        "Recursive",
        "Both same",
        "Depends on array"
        ],
        "correctAnswer": 0,
        "explanation": "Iterative Binary Search uses O(1) space; recursion uses O(log n) stack."
    },
    {
        "id": 280,
        "topic": "Paradigms",
        "algorithm": "Divide & Conquer : Binary Search",
        "difficulty": "Medium",
        "question": "Binary Search can be adapted for which type of problem?",
        "options": [
        "Finding first/last occurrence",
        "Sorting array",
        "Linear search",
        "Counting elements"
        ],
        "correctAnswer": 0,
        "explanation": "Binary Search can locate first/last occurrence in sorted arrays."
    },
    {
        "id": 281,
        "topic": "Paradigms",
        "algorithm": "Divide & Conquer : Binary Search",
        "difficulty": "Hard",
        "question": "Which variant works on rotated sorted arrays?",
        "options": [
        "Modified Binary Search",
        "Standard Binary Search",
        "Linear search",
        "Quick Search"
        ],
        "correctAnswer": 0,
        "explanation": "Modified Binary Search accounts for rotation to find target correctly."
    },
    {
        "id": 282,
        "topic": "Paradigms",
        "algorithm": "Divide & Conquer : Binary Search",
        "difficulty": "Hard",
        "question": "Binary Search in infinite or unknown size array?",
        "options": [
        "Exponential search followed by Binary Search",
        "Linear search",
        "Quick Search",
        "Merge Search"
        ],
        "correctAnswer": 0,
        "explanation": "Exponential search finds a range, then binary search locates the element."
    },

    {
        "id": 283,
        "topic": "Paradigms",
        "algorithm": "Divide & Conquer : Maximum Subarray Sum",
        "difficulty": "Easy",
        "question": "What is the goal of Maximum Subarray Sum problem?",
        "options": [
        "Find contiguous subarray with maximum sum",
        "Sort array",
        "Find largest element",
        "Count subarrays"
        ],
        "correctAnswer": 0,
        "explanation": "We seek a contiguous subarray whose sum is maximum."
    },
    {
        "id": 284,
        "topic": "Paradigms",
        "algorithm": "Divide & Conquer : Maximum Subarray Sum",
        "difficulty": "Easy",
        "question": "Which simple algorithm can solve it in O(n^2)?",
        "options": [
        "Check all subarrays",
        "Binary search",
        "Greedy selection",
        "Merge sort"
        ],
        "correctAnswer": 0,
        "explanation": "Brute-force checks sums of all possible contiguous subarrays."
    },
    {
        "id": 285,
        "topic": "Paradigms",
        "algorithm": "Divide & Conquer : Maximum Subarray Sum",
        "difficulty": "Medium",
        "question": "Optimal O(n) algorithm is called?",
        "options": [
        "Kadanes algorithm",
        "Merge Sum",
        "Divide Sum",
        "Quick Sum"
        ],
        "correctAnswer": 0,
        "explanation": "Kadanes algorithm computes max sum in linear time using DP-like approach."
    },
    {
        "id": 286,
        "topic": "Paradigms",
        "algorithm": "Divide & Conquer : Maximum Subarray Sum",
        "difficulty": "Medium",
        "question": "Kadanes algorithm keeps track of?",
        "options": [
        "Current max ending here and overall max",
        "All subarrays",
        "Sum of first half",
        "Count of positive numbers"
        ],
        "correctAnswer": 0,
        "explanation": "It maintains current subarray sum and updates overall maximum."
    },
    {
        "id": 287,
        "topic": "Paradigms",
        "algorithm": "Divide & Conquer : Maximum Subarray Sum",
        "difficulty": "Hard",
        "question": "Time complexity of Kadanes algorithm?",
        "options": [
        "O(n)",
        "O(n log n)",
        "O(n^2)",
        "O(log n)"
        ],
        "correctAnswer": 0,
        "explanation": "Each element is processed once, giving linear O(n) complexity."
    },
    {
        "id": 288,
        "topic": "Paradigms",
        "algorithm": "Divide & Conquer : Maximum Subarray Sum",
        "difficulty": "Hard",
        "question": "Can Kadanes algorithm handle all-negative arrays?",
        "options": [
        "Yes, by tracking maximum element",
        "No",
        "Only positive arrays",
        "Depends on size"
        ],
        "correctAnswer": 0,
        "explanation": "It works for all-negative arrays by choosing the maximum single element."
    },
    {
        "id": 289,
        "topic": "Other Topics",
        "algorithm": "trees: Preorder Traversal",
        "difficulty": "Easy",
        "question": "What is the order of nodes in Preorder Traversal?",
        "options": [
        "Root, Left, Right",
        "Left, Root, Right",
        "Left, Right, Root",
        "Right, Root, Left"
        ],
        "correctAnswer": 0,
        "explanation": "Preorder traversal visits the root first, then the left subtree, then the right subtree."
    },
    {
        "id": 290,
        "topic": "Other Topics",
        "algorithm": "trees: Preorder Traversal",
        "difficulty": "Easy",
        "question": "Preorder traversal is typically implemented using?",
        "options": [
        "Recursion or stack",
        "Queue only",
        "Heap",
        "Graph"
        ],
        "correctAnswer": 0,
        "explanation": "Recursion or an explicit stack is used to simulate recursive calls."
    },
    {
        "id": 291,
        "topic": "Other Topics",
        "algorithm": "trees: Preorder Traversal",
        "difficulty": "Medium",
        "question": "Time complexity of Preorder Traversal?",
        "options": [
        "O(n)",
        "O(n log n)",
        "O(log n)",
        "O(n^2)"
        ],
        "correctAnswer": 0,
        "explanation": "Each node is visited once, giving O(n) time complexity."
    },
    {
        "id": 292,
        "topic": "Other Topics",
        "algorithm": "trees: Preorder Traversal",
        "difficulty": "Medium",
        "question": "Which data structure can be used for iterative preorder traversal?",
        "options": [
        "Stack",
        "Queue",
        "Heap",
        "Linked list"
        ],
        "correctAnswer": 0,
        "explanation": "A stack simulates the recursive calls for preorder traversal."
    },
    {
        "id": 293,
        "topic": "Other Topics",
        "algorithm": "trees: Preorder Traversal",
        "difficulty": "Hard",
        "question": "Preorder traversal is used to?",
        "options": [
        "Serialize a tree",
        "Sort elements",
        "Search efficiently",
        "Delete nodes"
        ],
        "correctAnswer": 0,
        "explanation": "Preorder is often used for tree serialization and reconstruction."
    },
    {
        "id": 294,
        "topic": "Other Topics",
        "algorithm": "trees: Preorder Traversal",
        "difficulty": "Hard",
        "question": "Space complexity of recursive Preorder Traversal?",
        "options": [
        "O(h) where h is tree height",
        "O(n)",
        "O(log n)",
        "O(1)"
        ],
        "correctAnswer": 0,
        "explanation": "Recursive calls stack can go up to the height of the tree."
    },

    {
        "id": 295,
        "topic": "Other Topics",
        "algorithm": "trees: Inorder Traversal",
        "difficulty": "Easy",
        "question": "Order of nodes in Inorder Traversal?",
        "options": [
        "Left, Root, Right",
        "Root, Left, Right",
        "Right, Root, Left",
        "Left, Right, Root"
        ],
        "correctAnswer": 0,
        "explanation": "Inorder visits left subtree, then root, then right subtree."
    },
    {
        "id": 296,
        "topic": "Other Topics",
        "algorithm": "trees: Inorder Traversal",
        "difficulty": "Easy",
        "question": "Inorder traversal of a BST gives?",
        "options": [
        "Sorted sequence",
        "Reverse sorted sequence",
        "Random order",
        "Heap order"
        ],
        "correctAnswer": 0,
        "explanation": "Inorder traversal of a BST visits nodes in ascending order."
    },
    {
        "id": 297,
        "topic": "Other Topics",
        "algorithm": "trees: Inorder Traversal",
        "difficulty": "Medium",
        "question": "Iterative Inorder traversal uses?",
        "options": [
        "Stack",
        "Queue",
        "Heap",
        "Graph"
        ],
        "correctAnswer": 0,
        "explanation": "A stack is used to track nodes while visiting leftmost nodes first."
    },
    {
        "id": 298,
        "topic": "Other Topics",
        "algorithm": "trees: Inorder Traversal",
        "difficulty": "Medium",
        "question": "Time complexity of Inorder Traversal?",
        "options": [
        "O(n)",
        "O(n log n)",
        "O(log n)",
        "O(n^2)"
        ],
        "correctAnswer": 0,
        "explanation": "Each node is visited exactly once, O(n)."
    },
    {
        "id": 299,
        "topic": "Other Topics",
        "algorithm": "trees: Inorder Traversal",
        "difficulty": "Hard",
        "question": "Morris Traversal for Inorder achieves?",
        "options": [
        "O(1) space",
        "O(n log n) time",
        "Stack-based simulation",
        "Heap-based storage"
        ],
        "correctAnswer": 0,
        "explanation": "Morris Traversal uses threaded binary tree concept to traverse in O(1) space."
    },
    {
        "id": 300,
        "topic": "Other Topics",
        "algorithm": "trees: Inorder Traversal",
        "difficulty": "Hard",
        "question": "Inorder is useful to?",
        "options": [
        "Validate BST property",
        "Compute height",
        "Delete node",
        "Traverse level-wise"
        ],
        "correctAnswer": 0,
        "explanation": "Inorder traversal of a BST should produce a sorted sequence; this validates BST."
    },
    {
        "id": 301,
        "topic": "Other Topics",
        "algorithm": "trees: Postorder Traversal",
        "difficulty": "Easy",
        "question": "Order of nodes in Postorder Traversal?",
        "options": [
        "Left, Right, Root",
        "Root, Left, Right",
        "Left, Root, Right",
        "Right, Root, Left"
        ],
        "correctAnswer": 0,
        "explanation": "Postorder visits left subtree, then right subtree, then root."
    },
    {
        "id": 302,
        "topic": "Other Topics",
        "algorithm": "trees: Postorder Traversal",
        "difficulty": "Easy",
        "question": "Postorder traversal is useful for?",
        "options": [
        "Deleting a tree",
        "Printing nodes",
        "Searching elements",
        "Balancing tree"
        ],
        "correctAnswer": 0,
        "explanation": "Postorder is used to delete a tree safely by visiting children first."
    },
    {
        "id": 303,
        "topic": "Other Topics",
        "algorithm": "trees: Postorder Traversal",
        "difficulty": "Medium",
        "question": "Iterative Postorder traversal can use?",
        "options": [
        "Two stacks",
        "Queue",
        "Heap",
        "Graph"
        ],
        "correctAnswer": 0,
        "explanation": "Two stacks can simulate postorder traversal iteratively."
    },
    {
        "id": 304,
        "topic": "Other Topics",
        "algorithm": "trees: Postorder Traversal",
        "difficulty": "Medium",
        "question": "Time complexity of Postorder Traversal?",
        "options": [
        "O(n)",
        "O(n log n)",
        "O(log n)",
        "O(n^2)"
        ],
        "correctAnswer": 0,
        "explanation": "Each node is visited once."
    },
    {
        "id": 305,
        "topic": "Other Topics",
        "algorithm": "trees: Postorder Traversal",
        "difficulty": "Hard",
        "question": "Space complexity of recursive Postorder?",
        "options": [
        "O(h) where h is tree height",
        "O(n)",
        "O(log n)",
        "O(1)"
        ],
        "correctAnswer": 0,
        "explanation": "Recursive calls stack can go up to tree height."
    },
    {
        "id": 306,
        "topic": "Other Topics",
        "algorithm": "trees: Postorder Traversal",
        "difficulty": "Hard",
        "question": "Postorder can be used to compute?",
        "options": [
        "Subtree sizes or expression evaluation",
        "Node heights only",
        "Inorder sequence",
        "Level order sequence"
        ],
        "correctAnswer": 0,
        "explanation": "Postorder allows processing children before root, useful in evaluation and subtree computations."
    },

    {
        "id": 307,
        "topic": "Other Topics",
        "algorithm": "trees: Level Order Traversal",
        "difficulty": "Easy",
        "question": "Level Order Traversal visits nodes in?",
        "options": [
        "Breadth-first manner",
        "Depth-first manner",
        "Random order",
        "Reverse order"
        ],
        "correctAnswer": 0,
        "explanation": "Level order uses BFS to visit nodes level by level."
    },
    {
        "id": 308,
        "topic": "Other Topics",
        "algorithm": "trees: Level Order Traversal",
        "difficulty": "Easy",
        "question": "Which data structure is used for Level Order Traversal?",
        "options": [
        "Queue",
        "Stack",
        "Heap",
        "Graph"
        ],
        "correctAnswer": 0,
        "explanation": "Queue stores nodes of each level to process in FIFO order."
    },
    {
        "id": 309,
        "topic": "Other Topics",
        "algorithm": "trees: Level Order Traversal",
        "difficulty": "Medium",
        "question": "Time complexity of Level Order Traversal?",
        "options": [
        "O(n)",
        "O(n log n)",
        "O(log n)",
        "O(n^2)"
        ],
        "correctAnswer": 0,
        "explanation": "Each node is visited once."
    },
    {
        "id": 310,
        "topic": "Other Topics",
        "algorithm": "trees: Level Order Traversal",
        "difficulty": "Medium",
        "question": "Level order can also be called?",
        "options": [
        "Breadth-First Traversal",
        "Depth-First Traversal",
        "Preorder Traversal",
        "Inorder Traversal"
        ],
        "correctAnswer": 0,
        "explanation": "Level order is equivalent to BFS."
    },
    {
        "id": 311,
        "topic": "Other Topics",
        "algorithm": "trees: Level Order Traversal",
        "difficulty": "Hard",
        "question": "Space complexity of level order traversal?",
        "options": [
        "O(width of tree)",
        "O(h)",
        "O(n log n)",
        "O(n^2)"
        ],
        "correctAnswer": 0,
        "explanation": "Queue stores up to the maximum number of nodes at any level."
    },
    {
        "id": 312,
        "topic": "Other Topics",
        "algorithm": "trees: Level Order Traversal",
        "difficulty": "Hard",
        "question": "Level order can be used to compute?",
        "options": [
        "Height of tree, level sums, zigzag traversal",
        "Only leaf nodes",
        "Inorder sequence",
        "Preorder sequence"
        ],
        "correctAnswer": 0,
        "explanation": "It allows computations involving levels like height, sum, or zigzag ordering."
    },

    {
        "id": 313,
        "topic": "Other Topics",
        "algorithm": "trees: BST Insert",
        "difficulty": "Easy",
        "question": "In BST, where is a new node inserted?",
        "options": [
        "Maintaining BST property",
        "At root always",
        "Leftmost position",
        "Rightmost position"
        ],
        "correctAnswer": 0,
        "explanation": "BST insertion ensures left < root < right property."
    },
    {
        "id": 314,
        "topic": "Other Topics",
        "algorithm": "trees: BST Insert",
        "difficulty": "Easy",
        "question": "Time complexity of BST insertion (balanced tree)?",
        "options": [
        "O(log n)",
        "O(n)",
        "O(n log n)",
        "O(1)"
        ],
        "correctAnswer": 0,
        "explanation": "Balanced BST has height log n, giving O(log n) insertion time."
    },
    {
        "id": 315,
        "topic": "Other Topics",
        "algorithm": "trees: BST Insert",
        "difficulty": "Medium",
        "question": "Insertion in BST may cause?",
        "options": [
        "Tree imbalance (for unbalanced BST)",
        "Tree deletion",
        "Traversal change",
        "Sorting error"
        ],
        "correctAnswer": 0,
        "explanation": "Unbalanced insertions may skew the tree."
    },
    {
        "id": 316,
        "topic": "Other Topics",
        "algorithm": "trees: BST Insert",
        "difficulty": "Medium",
        "question": "BST insertion can be implemented using?",
        "options": [
        "Recursion or iteration",
        "Queue only",
        "Heap only",
        "Graph traversal"
        ],
        "correctAnswer": 0,
        "explanation": "Both recursive and iterative methods are used for BST insertion."
    },
    {
        "id": 317,
        "topic": "Other Topics",
        "algorithm": "trees: BST Insert",
        "difficulty": "Hard",
        "question": "Time complexity of BST insertion in worst-case (skewed tree)?",
        "options": [
        "O(n)",
        "O(log n)",
        "O(n log n)",
        "O(1)"
        ],
        "correctAnswer": 0,
        "explanation": "A skewed BST has height n, giving O(n) insertion time."
    },
    {
        "id": 318,
        "topic": "Other Topics",
        "algorithm": "trees: BST Insert",
        "difficulty": "Hard",
        "question": "BST insertion maintains?",
        "options": [
        "BST property",
        "Heap property",
        "Graph adjacency",
        "Traversal order"
        ],
        "correctAnswer": 0,
        "explanation": "Insertion ensures BST left < root < right property."
    },
    {
        "id": 319,
        "topic": "Other Topics",
        "algorithm": "trees: BST Search",
        "difficulty": "Easy",
        "question": "In a BST, how do you search for a value?",
        "options": [
        "Compare with root and traverse left or right",
        "Check all nodes sequentially",
        "Use a hash table",
        "Random traversal"
        ],
        "correctAnswer": 0,
        "explanation": "BST search compares the target with root and moves left or right recursively or iteratively."
    },
    {
        "id": 320,
        "topic": "Other Topics",
        "algorithm": "trees: BST Search",
        "difficulty": "Easy",
        "question": "Time complexity of BST search in a balanced tree?",
        "options": [
        "O(log n)",
        "O(n)",
        "O(n log n)",
        "O(1)"
        ],
        "correctAnswer": 0,
        "explanation": "Balanced BST has height log n, so search takes O(log n)."
    },
    {
        "id": 321,
        "topic": "Other Topics",
        "algorithm": "trees: BST Search",
        "difficulty": "Medium",
        "question": "Time complexity of BST search in worst-case (skewed tree)?",
        "options": [
        "O(n)",
        "O(log n)",
        "O(n log n)",
        "O(1)"
        ],
        "correctAnswer": 0,
        "explanation": "A skewed BST has height n, so search can take O(n) in worst case."
    },
    {
        "id": 322,
        "topic": "Other Topics",
        "algorithm": "trees: BST Search",
        "difficulty": "Medium",
        "question": "BST search can be implemented using?",
        "options": [
        "Recursion or iteration",
        "Queue only",
        "Heap only",
        "Stack only"
        ],
        "correctAnswer": 0,
        "explanation": "Both recursive and iterative approaches are commonly used."
    },
    {
        "id": 323,
        "topic": "Other Topics",
        "algorithm": "trees: BST Search",
        "difficulty": "Hard",
        "question": "Searching a non-existent element in BST returns?",
        "options": [
        "Null or None",
        "Root node",
        "Random node",
        "All nodes"
        ],
        "correctAnswer": 0,
        "explanation": "If the element is not found, search returns null (or None in Python)."
    },
    {
        "id": 324,
        "topic": "Other Topics",
        "algorithm": "trees: BST Search",
        "difficulty": "Hard",
        "question": "BST search efficiency depends on?",
        "options": [
        "Tree height",
        "Node values",
        "Queue usage",
        "Traversal type"
        ],
        "correctAnswer": 0,
        "explanation": "Search efficiency is determined by tree height; balanced trees give O(log n)."
    },

    {
        "id": 325,
        "topic": "Other Topics",
        "algorithm": "trees: BST Delete",
        "difficulty": "Easy",
        "question": "Deleting a node with no children in BST?",
        "options": [
        "Simply remove the node",
        "Replace with root",
        "Move left subtree",
        "Move right subtree"
        ],
        "correctAnswer": 0,
        "explanation": "A leaf node can be removed directly without affecting BST property."
    },
    {
        "id": 326,
        "topic": "Other Topics",
        "algorithm": "trees: BST Delete",
        "difficulty": "Easy",
        "question": "Deleting a node with one child?",
        "options": [
        "Replace node with its child",
        "Replace with root",
        "Remove both subtrees",
        "Do nothing"
        ],
        "correctAnswer": 0,
        "explanation": "The node is replaced by its only child to maintain BST property."
    },
    {
        "id": 327,
        "topic": "Other Topics",
        "algorithm": "trees: BST Delete",
        "difficulty": "Medium",
        "question": "Deleting a node with two children?",
        "options": [
        "Replace with inorder successor or predecessor",
        "Remove both subtrees",
        "Replace with root",
        "Random node"
        ],
        "correctAnswer": 0,
        "explanation": "Replace the node with its inorder successor (or predecessor) and delete that successor."
    },
    {
        "id": 328,
        "topic": "Other Topics",
        "algorithm": "trees: BST Delete",
        "difficulty": "Medium",
        "question": "Time complexity of BST delete (balanced tree)?",
        "options": [
        "O(log n)",
        "O(n)",
        "O(n log n)",
        "O(1)"
        ],
        "correctAnswer": 0,
        "explanation": "Delete involves search plus adjustment, giving O(log n) in balanced BST."
    },
    {
        "id": 329,
        "topic": "Other Topics",
        "algorithm": "trees: BST Delete",
        "difficulty": "Hard",
        "question": "Time complexity of BST delete (skewed tree)?",
        "options": [
        "O(n)",
        "O(log n)",
        "O(n log n)",
        "O(1)"
        ],
        "correctAnswer": 0,
        "explanation": "Skewed BST has height n, so delete can take O(n)."
    },
    {
        "id": 330,
        "topic": "Other Topics",
        "algorithm": "trees: BST Delete",
        "difficulty": "Hard",
        "question": "BST delete maintains?",
        "options": [
        "BST property",
        "Heap property",
        "Queue order",
        "Traversal order"
        ],
        "correctAnswer": 0,
        "explanation": "Deletion preserves the BST left < root < right property."
    },
    {
        "id": 331,
        "topic": "Other Topics",
        "algorithm": "A* Algorithm",
        "difficulty": "Easy",
        "question": "What is the main goal of the A* algorithm?",
        "options": [
            "Find the shortest path between two nodes",
            "Sort a list of elements",
            "Detect a cycle in a graph",
            "Compress data efficiently"
        ],
        "correctAnswer": 0,
        "explanation": "A* is used to find the shortest path between two points using cost and heuristic functions."
    },
    {
        "id": 332,
        "topic": "Other Topics",
        "algorithm": "A* Algorithm",
        "difficulty": "Easy",
        "question": "Which function guides A* towards the goal?",
        "options": [
            "Heuristic function (h)",
            "Stack function",
            "Compression ratio",
            "Hash function"
        ],
        "correctAnswer": 0,
        "explanation": "The heuristic function estimates the cost from the current node to the goal."
    },
    {
        "id": 333,
        "topic": "Other Topics",
        "algorithm": "A* Algorithm",
        "difficulty": "Medium",
        "question": "What is the evaluation function used by A*?",
        "options": [
            "f(n) = g(n) + h(n)",
            "f(n) = g(n) - h(n)",
            "f(n) = g(n) * h(n)",
            "f(n) = g(n) / h(n)"
        ],
        "correctAnswer": 0,
        "explanation": "A* uses f(n) = g(n) + h(n) where g(n) is path cost so far and h(n) is the heuristic estimate."
    },
    {
        "id": 334,
        "topic": "Other Topics",
        "algorithm": "A* Algorithm",
        "difficulty": "Medium",
        "question": "A* guarantees the shortest path if:",
        "options": [
            "The heuristic is admissible",
            "The heuristic is random",
            "The path has cycles",
            "The graph is unweighted"
        ],
        "correctAnswer": 0,
        "explanation": "An admissible heuristic never overestimates the true cost, ensuring optimality."
    },
    {
        "id": 335,
        "topic": "Other Topics",
        "algorithm": "A* Algorithm",
        "difficulty": "Hard",
        "question": "Which data structure is typically used to select the next node in A*?",
        "options": [
            "Priority Queue (Min-Heap)",
            "Stack",
            "Linked List",
            "Hash Table"
        ],
        "correctAnswer": 0,
        "explanation": "A* uses a priority queue to always expand the node with the lowest f(n) value."
    },
    {
        "id": 336,
        "topic": "Other Topics",
        "algorithm": "A* Algorithm",
        "difficulty": "Hard",
        "question": "When does A* perform like Dijkstras algorithm?",
        "options": [
            "When the heuristic h(n) = 0",
            "When h(n) > actual cost",
            "When graph is cyclic",
            "When g(n) is constant"
        ],
        "correctAnswer": 0,
        "explanation": "If the heuristic is zero, A* becomes equivalent to Dijkstras algorithm."
    },
    {
        "id": 337,
        "topic": "Other Topics",
        "algorithm": "Huffman Coding",
        "difficulty": "Easy",
        "question": "Huffman coding is mainly used for?",
        "options": [
            "Data compression",
            "Sorting arrays",
            "Graph traversal",
            "Pattern matching"
        ],
        "correctAnswer": 0,
        "explanation": "Huffman coding compresses data by assigning shorter codes to frequent characters."
    },
    {
        "id": 338,
        "topic": "Other Topics",
        "algorithm": "Huffman Coding",
        "difficulty": "Easy",
        "question": "What kind of tree does Huffman coding use?",
        "options": [
            "Binary Tree",
            "AVL Tree",
            "Trie",
            "B-Tree"
        ],
        "correctAnswer": 0,
        "explanation": "Huffman coding constructs a binary tree where leaves represent characters."
    },
    {
        "id": 339,
        "topic": "Other Topics",
        "algorithm": "Huffman Coding",
        "difficulty": "Medium",
        "question": "Which nodes are combined first in Huffman coding?",
        "options": [
            "Two lowest-frequency nodes",
            "Two highest-frequency nodes",
            "Random nodes",
            "Middle-frequency nodes"
        ],
        "correctAnswer": 0,
        "explanation": "The two smallest frequency nodes are merged to form a new node repeatedly."
    },
    {
        "id": 340,
        "topic": "Other Topics",
        "algorithm": "Huffman Coding",
        "difficulty": "Medium",
        "question": "The time complexity of building a Huffman Tree is?",
        "options": [
            "O(n log n)",
            "O(n)",
            "O(log n)",
            "O(n)"
        ],
        "correctAnswer": 0,
        "explanation": "Building the Huffman Tree involves sorting or using a min-heap, giving O(n log n)."
    },
    {
        "id": 341,
        "topic": "Other Topics",
        "algorithm": "Huffman Coding",
        "difficulty": "Hard",
        "question": "Huffman coding is optimal when:",
        "options": [
            "Symbol probabilities are known and independent",
            "Data is random",
            "Symbols repeat uniformly",
            "Compression ratio is fixed"
        ],
        "correctAnswer": 0,
        "explanation": "It gives the best compression when symbol frequencies are known and independent."
    },
    {
        "id": 342,
        "topic": "Other Topics",
        "algorithm": "Huffman Coding",
        "difficulty": "Hard",
        "question": "Which limitation does Huffman coding have?",
        "options": [
            "Does not handle variable-length sequences efficiently",
            "Cannot adapt to changing frequencies",
            "Cannot represent binary data",
            "Always increases data size"
        ],
        "correctAnswer": 1,
        "explanation": "Huffman coding is static; adaptive Huffman handles changing frequencies better."
    },
    {
        "id": 343,
        "topic": "Other Topics",
        "algorithm": "KMP Algorithm",
        "difficulty": "Easy",
        "question": "What problem does the KMP algorithm solve?",
        "options": [
            "Pattern matching in strings",
            "Shortest path finding",
            "Data compression",
            "Sorting characters"
        ],
        "correctAnswer": 0,
        "explanation": "KMP is used for pattern searching within a text efficiently."
    },
    {
        "id": 344,
        "topic": "Other Topics",
        "algorithm": "KMP Algorithm",
        "difficulty": "Easy",
        "question": "What is the main advantage of KMP over the naive approach?",
        "options": [
            "It avoids re-checking characters",
            "It uses less memory",
            "It sorts strings faster",
            "It compresses data"
        ],
        "correctAnswer": 0,
        "explanation": "KMP avoids redundant comparisons by precomputing information in the LPS array."
    },
    {
        "id": 345,
        "topic": "Other Topics",
        "algorithm": "KMP Algorithm",
        "difficulty": "Medium",
        "question": "What does the LPS array represent in KMP?",
        "options": [
            "Longest proper prefix which is also a suffix",
            "Least possible substring",
            "Length of processed string",
            "Lexicographically smallest prefix"
        ],
        "correctAnswer": 0,
        "explanation": "The LPS array stores the length of the longest proper prefix that is also a suffix."
    },
    {
        "id": 346,
        "topic": "Other Topics",
        "algorithm": "KMP Algorithm",
        "difficulty": "Medium",
        "question": "Time complexity of KMP pattern matching is?",
        "options": [
            "O(n + m)",
            "O(n * m)",
            "O(log n)",
            "O(n)"
        ],
        "correctAnswer": 0,
        "explanation": "KMP processes both text and pattern once, leading to O(n + m) complexity."
    },
    {
        "id": 347,
        "topic": "Other Topics",
        "algorithm": "KMP Algorithm",
        "difficulty": "Hard",
        "question": "In KMP, when a mismatch occurs, what determines the next shift of the pattern?",
        "options": [
            "The LPS array value of the previous index",
            "The position of mismatch",
            "Random offset",
            "Character ASCII difference"
        ],
        "correctAnswer": 0,
        "explanation": "The LPS array tells where to resume matching without re-checking characters."
    },
    {
        "id": 348,
        "topic": "Other Topics",
        "algorithm": "KMP Algorithm",
        "difficulty": "Hard",
        "question": "What is a key limitation of KMP in practical applications?",
        "options": [
            "High preprocessing time for short patterns",
            "Cannot handle binary data",
            "Requires sorted text",
            "Fails on repeating characters"
        ],
        "correctAnswer": 0,
        "explanation": "KMPs preprocessing (LPS table) can be unnecessary overhead for small or one-time searches."
    },
    {
        "id": 349,
        "topic": "Other Topics",
        "algorithm": "Rabin-Karp Algorithm",
        "difficulty": "Easy",
        "question": "What is the Rabin-Karp algorithm mainly used for?",
        "options": [
            "Pattern searching in strings",
            "Finding shortest paths",
            "Sorting arrays",
            "Building trees"
        ],
        "correctAnswer": 0,
        "explanation": "Rabin-Karp is a string-searching algorithm that uses hashing to find a pattern in a text."
    },
    {
        "id": 350,
        "topic": "Other Topics",
        "algorithm": "Rabin-Karp Algorithm",
        "difficulty": "Easy",
        "question": "What technique does Rabin-Karp use to compare substrings efficiently?",
        "options": [
            "Hashing",
            "Dynamic programming",
            "Binary search",
            "Recursion"
        ],
        "correctAnswer": 0,
        "explanation": "Rabin-Karp uses rolling hash functions to compare substring hashes instead of characters."
    },
    {
        "id": 351,
        "topic": "Other Topics",
        "algorithm": "Rabin-Karp Algorithm",
        "difficulty": "Medium",
        "question": "What is the average time complexity of Rabin-Karp?",
        "options": [
            "O(n + m)",
            "O(nm)",
            "O(log n)",
            "O(1)"
        ],
        "correctAnswer": 0,
        "explanation": "On average, Rabin-Karp performs efficiently in O(n + m) time using rolling hashes."
    },
    {
        "id": 352,
        "topic": "Other Topics",
        "algorithm": "Rabin-Karp Algorithm",
        "difficulty": "Medium",
        "question": "What causes Rabin-Karp to perform poorly in the worst case?",
        "options": [
            "Hash collisions",
            "Large input size",
            "Recursion overhead",
            "Pattern mismatch"
        ],
        "correctAnswer": 0,
        "explanation": "When hash collisions occur frequently, extra character comparisons cause O(nm) time."
    },
    {
        "id": 353,
        "topic": "Other Topics",
        "algorithm": "Rabin-Karp Algorithm",
        "difficulty": "Hard",
        "question": "Rabin-Karp uses a rolling hash to:",
        "options": [
            "Compute next substring hash in O(1)",
            "Recompute entire hash from scratch",
            "Store previous substring only",
            "Encrypt the pattern"
        ],
        "correctAnswer": 0,
        "explanation": "Rolling hash updates the hash value in constant time as the window slides across text."
    },
    {
        "id": 354,
        "topic": "Other Topics",
        "algorithm": "Rabin-Karp Algorithm",
        "difficulty": "Hard",
        "question": "Which of the following is an example of a good modulus for Rabin-Karp hashing?",
        "options": [
            "A large prime number",
            "A power of two",
            "A random integer",
            "The ASCII value of a character"
        ],
        "correctAnswer": 0,
        "explanation": "Using a large prime modulus minimizes collisions in the hash values."
    },
    {
        "id": 355,
        "topic": "Data Structures",
        "algorithm": "Stack Visualization",
        "difficulty": "Easy",
        "question": "Which operation adds an element to the top of a stack?",
        "options": [
            "Push",
            "Pop",
            "Peek",
            "Insert"
        ],
        "correctAnswer": 0,
        "explanation": "Push adds an element to the top of the stack."
    },
    {
        "id": 356,
        "topic": "Data Structures",
        "algorithm": "Stack Visualization",
        "difficulty": "Easy",
        "question": "Which operation removes the top element from a stack?",
        "options": [
            "Pop",
            "Push",
            "Peek",
            "Delete"
        ],
        "correctAnswer": 0,
        "explanation": "Pop removes the top element from the stack."
    },
    {
        "id": 357,
        "topic": "Data Structures",
        "algorithm": "Stack Visualization",
        "difficulty": "Medium",
        "question": "What does the Peek operation do on a stack?",
        "options": [
            "Returns the top element without removing it",
            "Removes the top element",
            "Adds an element at the bottom",
            "Checks if the stack is empty"
        ],
        "correctAnswer": 0,
        "explanation": "Peek lets you see the top element without modifying the stack."
    },
    {
        "id": 358,
        "topic": "Data Structures",
        "algorithm": "Stack Visualization",
        "difficulty": "Medium",
        "question": "Time complexity of push and pop in a stack is?",
        "options": [
            "O(1)",
            "O(n)",
            "O(log n)",
            "O(n log n)"
        ],
        "correctAnswer": 0,
        "explanation": "Both push and pop are constant-time operations."
    },
    {
        "id": 359,
        "topic": "Data Structures",
        "algorithm": "Stack Visualization",
        "difficulty": "Hard",
        "question": "Which scenario illustrates a stack overflow?",
        "options": [
            "Trying to push onto a full stack",
            "Trying to pop from an empty stack",
            "Viewing the top element",
            "Traversing the stack"
        ],
        "correctAnswer": 0,
        "explanation": "Stack overflow happens when you try to push beyond its capacity."
    },
    {
        "id": 360,
        "topic": "Data Structures",
        "algorithm": "Stack Visualization",
        "difficulty": "Hard",
        "question": "Which stack implementation supports dynamic memory usage efficiently?",
        "options": [
            "Linked list",
            "Fixed-size array",
            "Queue",
            "Binary tree"
        ],
        "correctAnswer": 0,
        "explanation": "Linked lists allow dynamic growth without a fixed size."
    },
    {
        "id": 361,
        "topic": "Other Topics",
        "algorithm": "Cycle Detection",
        "difficulty": "Easy",
        "question": "What is a cycle in a graph?",
        "options": [
            "A path that starts and ends at the same vertex",
            "A path visiting all vertices once",
            "A path with no repeated edges",
            "A disconnected component"
        ],
        "correctAnswer": 0,
        "explanation": "A cycle is a path where the first and last vertices are the same."
    },
    {
        "id": 362,
        "topic": "Other Topics",
        "algorithm": "Cycle Detection",
        "difficulty": "Easy",
        "question": "Which data structure is commonly used to detect cycles in a graph?",
        "options": [
            "Visited set / recursion stack",
            "Queue",
            "Heap",
            "Trie"
        ],
        "correctAnswer": 0,
        "explanation": "DFS with a visited set or recursion stack is typically used to detect cycles."
    },
    {
        "id": 363,
        "topic": "Other Topics",
        "algorithm": "Cycle Detection",
        "difficulty": "Medium",
        "question": "Time complexity of cycle detection using DFS is?",
        "options": [
            "O(V + E)",
            "O(V)",
            "O(E)",
            "O(log V)"
        ],
        "correctAnswer": 0,
        "explanation": "DFS visits each vertex and edge once, giving O(V + E) time."
    },
    {
        "id": 364,
        "topic": "Other Topics",
        "algorithm": "Cycle Detection",
        "difficulty": "Medium",
        "question": "In a directed graph, a cycle is detected if a node is visited that is:",
        "options": [
            "Already in the recursion stack",
            "Already in the visited set only",
            "Disconnected from start",
            "Leaf node"
        ],
        "correctAnswer": 0,
        "explanation": "A back edge to a node in the recursion stack indicates a cycle in a directed graph."
    },
    {
        "id": 365,
        "topic": "Other Topics",
        "algorithm": "Cycle Detection",
        "difficulty": "Hard",
        "question": "Which algorithm can detect cycles in a directed graph using topological sorting?",
        "options": [
            "Kahn's Algorithm",
            "Dijkstra's Algorithm",
            "Prim's Algorithm",
            "Bellman-Ford Algorithm"
        ],
        "correctAnswer": 0,
        "explanation": "Kahns algorithm detects cycles by checking if topological sorting is possible."
    },
    {
        "id": 366,
        "topic": "Other Topics",
        "algorithm": "Cycle Detection",
        "difficulty": "Hard",
        "question": "Union-Find (Disjoint Set) can be used to detect cycles in which type of graph?",
        "options": [
            "Undirected graph",
            "Directed graph",
            "Weighted graph only",
            "Tree only"
        ],
        "correctAnswer": 0,
        "explanation": "Union-Find efficiently detects cycles in undirected graphs by checking if two vertices belong to the same set."
    } ,
    {
        "id": 367,
        "topic": "Other Topics",
        "algorithm": "Kadanes Algorithm",
        "difficulty": "Easy",
        "question": "What problem does Kadanes Algorithm solve?",
        "options": [
            "Finding maximum sum subarray",
            "Finding minimum spanning tree",
            "Detecting cycles in a graph",
            "Sorting an array"
        ],
        "correctAnswer": 0,
        "explanation": "Kadanes Algorithm finds the maximum sum of a contiguous subarray."
    },
    {
        "id": 368,
        "topic": "Other Topics",
        "algorithm": "Kadanes Algorithm",
        "difficulty": "Easy",
        "question": "What is the time complexity of Kadanes Algorithm?",
        "options": [
            "O(n)",
            "O(n)",
            "O(log n)",
            "O(n log n)"
        ],
        "correctAnswer": 0,
        "explanation": "Kadanes Algorithm runs in linear time O(n)."
    },
    {
        "id": 369,
        "topic": "Other Topics",
        "algorithm": "Prims Algorithm",
        "difficulty": "Easy",
        "question": "What type of graph problem does Prims Algorithm solve?",
        "options": [
            "Minimum Spanning Tree",
            "Shortest Path",
            "Cycle Detection",
            "Maximum Flow"
        ],
        "correctAnswer": 0,
        "explanation": "Prims Algorithm is used to find a minimum spanning tree."
    },
    {
        "id": 370,
        "topic": "Other Topics",
        "algorithm": "Prims Algorithm",
        "difficulty": "Easy",
        "question": "Prims Algorithm starts from:",
        "options": [
            "Any arbitrary vertex",
            "The vertex with the smallest degree",
            "The vertex with the largest degree",
            "The first vertex in the input"
        ],
        "correctAnswer": 0,
        "explanation": "Prims Algorithm can start from any vertex in the graph."
    },
    {
        "id": 371,
        "topic": "Other Topics",
        "algorithm": "Kruskals Algorithm",
        "difficulty": "Easy",
        "question": "What data structure is commonly used by Kruskals Algorithm to detect cycles?",
        "options": [
            "Disjoint Set (Union-Find)",
            "Stack",
            "Queue",
            "Priority Queue"
        ],
        "correctAnswer": 0,
        "explanation": "Disjoint Set (Union-Find) is used to detect cycles in Kruskals Algorithm."
    },
    {
        "id": 372,
        "topic": "Other Topics",
        "algorithm": "Kruskals Algorithm",
        "difficulty": "Easy",
        "question": "Which of the following best describes Kruskals Algorithm?",
        "options": [
            "Adds edges in increasing order of weight",
            "Adds vertices in decreasing order of degree",
            "Performs DFS to find cycles",
            "Uses dynamic programming"
        ],
        "correctAnswer": 0,
        "explanation": "Kruskals Algorithm adds edges in non-decreasing order of weight."
    },
    {
        "id": 373,
        "topic": "Other Topics",
        "algorithm": "Kadanes Algorithm",
        "difficulty": "Easy",
        "question": "Which of these arrays would Kadanes Algorithm process correctly?",
        "options": [
            "Array with both positive and negative numbers",
            "Only positive numbers",
            "Only negative numbers",
            "Only zeros"
        ],
        "correctAnswer": 0,
        "explanation": "Kadanes Algorithm works on arrays containing positive and negative numbers."
    },
    {
        "id": 374,
        "topic": "Other Topics",
        "algorithm": "Prims Algorithm",
        "difficulty": "Easy",
        "question": "Prims Algorithm can be implemented efficiently using:",
        "options": [
            "Priority Queue",
            "Stack",
            "Queue",
            "Linked List"
        ],
        "correctAnswer": 0,
        "explanation": "Priority Queue helps efficiently pick the next minimum edge in Prims Algorithm."
    },
    {
        "id": 375,
        "topic": "Other Topics",
        "algorithm": "Kruskals Algorithm",
        "difficulty": "Easy",
        "question": "Kruskals Algorithm requires the edges to be:",
        "options": [
            "Sorted by weight",
            "Sorted by vertex number",
            "Unsorted",
            "Sorted by color"
        ],
        "correctAnswer": 0,
        "explanation": "Edges are sorted by weight before processing in Kruskals Algorithm."
    },
    {
        "id": 376,
        "topic": "Other Topics",
        "algorithm": "Kadanes Algorithm",
        "difficulty": "Easy",
        "question": "Kadanes Algorithm is an example of:",
        "options": [
            "Dynamic Programming",
            "Greedy Algorithm",
            "Divide and Conquer",
            "Backtracking"
        ],
        "correctAnswer": 0,
        "explanation": "Kadanes Algorithm is a classic dynamic programming approach."
    },
    {
        "id": 377,
        "topic": "Other Topics",
        "algorithm": "Kadanes Algorithm",
        "difficulty": "Medium",
        "question": "How does Kadanes Algorithm handle negative sums when calculating maximum subarray?",
        "options": [
            "Resets current sum to zero when it becomes negative",
            "Ignores negative numbers",
            "Always adds negative numbers",
            "Stops immediately"
        ],
        "correctAnswer": 0,
        "explanation": "Kadanes resets the current sum when it drops below zero to maximize the sum."
    },
    {
        "id": 378,
        "topic": "Other Topics",
        "algorithm": "Kadanes Algorithm",
        "difficulty": "Medium",
        "question": "What is the space complexity of Kadanes Algorithm?",
        "options": [
            "O(1)",
            "O(n)",
            "O(log n)",
            "O(n)"
        ],
        "correctAnswer": 0,
        "explanation": "Kadanes Algorithm uses constant extra space."
    },
    {
        "id": 379,
        "topic": "Other Topics",
        "algorithm": "Prims Algorithm",
        "difficulty": "Medium",
        "question": "What data structure is typically used to implement Prims Algorithm efficiently?",
        "options": [
            "Min-Heap (Priority Queue)",
            "Stack",
            "Queue",
            "Array"
        ],
        "correctAnswer": 0,
        "explanation": "Min-Heap is used to efficiently pick the minimum weight edge."
    },
    {
        "id": 380,
        "topic": "Other Topics",
        "algorithm": "Prims Algorithm",
        "difficulty": "Medium",
        "question": "Prims Algorithm is guaranteed to work only on:",
        "options": [
            "Connected graphs",
            "Disconnected graphs",
            "Directed graphs",
            "Weighted graphs without cycles"
        ],
        "correctAnswer": 0,
        "explanation": "Prims Algorithm requires the graph to be connected."
    },
    {
        "id": 381,
        "topic": "Other Topics",
        "algorithm": "Kruskals Algorithm",
        "difficulty": "Medium",
        "question": "What is the overall time complexity of Kruskals Algorithm using a good Union-Find structure?",
        "options": [
            "O(E log E)",
            "O(V)",
            "O(E)",
            "O(V + E)"
        ],
        "correctAnswer": 0,
        "explanation": "Sorting edges dominates time complexity, O(E log E)."
    },
    {
        "id": 382,
        "topic": "Other Topics",
        "algorithm": "Kruskals Algorithm",
        "difficulty": "Medium",
        "question": "When does Kruskals Algorithm reject an edge while building MST?",
        "options": [
            "If adding the edge creates a cycle",
            "If the edge is the heaviest",
            "If the edge connects two disconnected components",
            "If the edge is not adjacent to the current tree"
        ],
        "correctAnswer": 0,
        "explanation": "Edges creating cycles are rejected to keep MST acyclic."
    },
    {
        "id": 383,
        "topic": "Other Topics",
        "algorithm": "Kadanes Algorithm",
        "difficulty": "Medium",
        "question": "If all numbers in the array are negative, Kadanes Algorithm should return:",
        "options": [
            "The maximum (least negative) element",
            "Zero",
            "Sum of all elements",
            "Minimum element"
        ],
        "correctAnswer": 0,
        "explanation": "Kadanes returns the maximum single element if all are negative."
    },
    {
        "id": 384,
        "topic": "Other Topics",
        "algorithm": "Prims Algorithm",
        "difficulty": "Medium",
        "question": "What happens if Prims Algorithm is applied to a disconnected graph?",
        "options": [
            "It finds MST for one connected component only",
            "It finds MST for the entire graph",
            "It fails with an error",
            "It converts graph to connected"
        ],
        "correctAnswer": 0,
        "explanation": "Prims only builds MST for the connected part it starts from."
    },
    {
        "id": 385,
        "topic": "Other Topics",
        "algorithm": "Kruskals Algorithm",
        "difficulty": "Medium",
        "question": "Which of the following edge selections is valid in Kruskals Algorithm?",
        "options": [
            "Edges that connect two different components",
            "Edges that form cycles",
            "Edges with maximum weight first",
            "Edges with the same vertices as previously selected edges"
        ],
        "correctAnswer": 0,
        "explanation": "Kruskals selects edges that connect different components to avoid cycles."
    },
    {
        "id": 386,
        "topic": "Other Topics",
        "algorithm": "Kadanes Algorithm",
        "difficulty": "Medium",
        "question": "Which technique does Kadanes Algorithm primarily use to solve the problem?",
        "options": [
            "Dynamic programming",
            "Greedy approach",
            "Divide and conquer",
            "Backtracking"
        ],
        "correctAnswer": 0,
        "explanation": "Kadanes Algorithm is based on dynamic programming principles."
    },
    {
        "id": 387,
        "topic": "Other Topics",
        "algorithm": "Kadanes Algorithm",
        "difficulty": "Hard",
        "question": "How can Kadanes Algorithm be modified to find the maximum product subarray instead of sum?",
        "options": [
            "Keep track of both maximum and minimum products at each step",
            "Use the sum instead of product",
            "Ignore negative numbers",
            "Sort the array before applying"
        ],
        "correctAnswer": 0,
        "explanation": "Tracking both max and min products handles negative values affecting the product."
    },
    {
        "id": 388,
        "topic": "Other Topics",
        "algorithm": "Kadanes Algorithm",
        "difficulty": "Hard",
        "question": "What is a key limitation of Kadanes Algorithm when applied directly to 2D arrays?",
        "options": [
            "It only works for 1D arrays",
            "It cannot handle negative numbers",
            "It requires sorted arrays",
            "It only works for positive numbers"
        ],
        "correctAnswer": 0,
        "explanation": "Kadanes is for 1D arrays; 2D maximum subarray requires extensions like fixing left and right boundaries."
    },
    {
        "id": 389,
        "topic": "Other Topics",
        "algorithm": "Prims Algorithm",
        "difficulty": "Hard",
        "question": "What is the worst-case time complexity of Prims Algorithm implemented with an adjacency matrix?",
        "options": [
            "O(V)",
            "O(E log V)",
            "O(V + E)",
            "O(V log V)"
        ],
        "correctAnswer": 0,
        "explanation": "Using adjacency matrix results in O(V) time complexity."
    },
    {
        "id": 390,
        "topic": "Other Topics",
        "algorithm": "Prims Algorithm",
        "difficulty": "Hard",
        "question": "How does the choice of data structure impact Prims Algorithms performance on sparse graphs?",
        "options": [
            "Min-heap reduces time complexity significantly",
            "Linked list improves performance",
            "Stack reduces complexity",
            "Queue is the best choice"
        ],
        "correctAnswer": 0,
        "explanation": "Using a min-heap with adjacency lists optimizes Prims to O(E log V) on sparse graphs."
    },
    {
        "id": 391,
        "topic": "Other Topics",
        "algorithm": "Kruskals Algorithm",
        "difficulty": "Hard",
        "question": "In Kruskals Algorithm, what optimization improves the efficiency of the Union-Find data structure?",
        "options": [
            "Union by rank and path compression",
            "Stack implementation",
            "Breadth-first search",
            "Sorting edges twice"
        ],
        "correctAnswer": 0,
        "explanation": "Union by rank and path compression optimize Union-Find operations to near O(1)."
    },
    {
        "id": 392,
        "topic": "Other Topics",
        "algorithm": "Kruskals Algorithm",
        "difficulty": "Hard",
        "question": "How does Kruskals Algorithm behave with graphs having multiple edges of the same weight?",
        "options": [
            "It can choose any edge among equals, resulting in multiple MSTs",
            "It always chooses the first edge",
            "It fails to find MST",
            "It sorts edges by vertex number"
        ],
        "correctAnswer": 0,
        "explanation": "Multiple MSTs can exist when edges have the same weight; Kruskals may produce any valid MST."
    },
    {
        "id": 393,
        "topic": "Other Topics",
        "algorithm": "Kadanes Algorithm",
        "difficulty": "Hard",
        "question": "Can Kadanes Algorithm be adapted to find the maximum sum of non-contiguous subarray? If yes, how?",
        "options": [
            "No, Kadanes is for contiguous subarrays only",
            "Yes, by modifying the algorithm to skip some elements",
            "Yes, by sorting the array first",
            "No, it works only on sorted arrays"
        ],
        "correctAnswer": 0,
        "explanation": "Kadanes Algorithm specifically solves the maximum sum contiguous subarray problem; non-contiguous requires different approach."
    },
    {
        "id": 394,
        "topic": "Other Topics",
        "algorithm": "Prims Algorithm",
        "difficulty": "Hard",
        "question": "How is Prims Algorithm modified to work on disconnected graphs?",
        "options": [
            "Run Prims on each connected component separately",
            "Add edges to connect components arbitrarily",
            "Ignore disconnected parts",
            "Use DFS before Prims"
        ],
        "correctAnswer": 0,
        "explanation": "To handle disconnected graphs, run Prims MST algorithm on each connected component."
    },
    {
        "id": 395,
        "topic": "Other Topics",
        "algorithm": "Kruskals Algorithm",
        "difficulty": "Hard",
        "question": "What is the impact on Kruskals Algorithm if the input graph is already a tree?",
        "options": [
            "The algorithm immediately returns the tree as MST",
            "It will add extra edges",
            "It will fail to complete",
            "It needs re-sorting edges"
        ],
        "correctAnswer": 0,
        "explanation": "If input is already a tree (no cycles, V-1 edges), Kruskals simply returns it as MST."
    },
    {
    "id": 396,
    "topic": "Other Topics",
    "algorithm": "Prims Algorithm",
    "difficulty": "Hard",
    "question": "In Prims Algorithm, if two edges have the same minimum weight during selection, what could be the possible consequence in a graph with multiple equal-weight edges?",
    "options": [
        "It may produce different but valid MSTs depending on the chosen edge",
        "The algorithm will enter an infinite loop",
        "The resulting MST will always be the same regardless of edge selection",
        "The algorithm will fail to find any MST"
    ],
    "correctAnswer": 0,
    "explanation": "When multiple edges have equal weights, Prims Algorithm may choose any of them, potentially resulting in different but equally valid minimum spanning trees since MSTs are not necessarily unique in such graphs."
}



]
                                                        


